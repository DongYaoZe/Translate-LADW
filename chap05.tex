\chapter{内积空间}

\section{$\mathbb{R}^n$ 与 $\mathbb{C}^n$ 中的内积~内积空间}

\section{正交性~正交与标准正交基}

\section{正交投影和格拉姆-施密特正交化}
回想一下二维平面几何中正交投影的定义，人们可以引入以下定义。设 $E$ 是内积空间 $V$ 的一个子空间。

\textbf{定义 3.1。} 对于向量 $v$，它到子空间 $E$ 的\textbf{正交投影} $P_E v$ 是一个向量 $w$，满足：
1. $w \in E$；
2. $v - w \perp E$。
我们将使用记号 $w = P_E v$ 表示正交投影。在引入一个对象之后，自然要问：1. 该对象是否存在？2. 该对象是否唯一？3. 如何找到它？我们将首先证明投影是唯一的。然后我们将给出一个找到投影的方法，证明它的存在。下面的定理表明了为什么正交投影很重要，同时也证明了它的唯一性。

\textbf{定理 3.2。} 正交投影 $w = P_E v$ 使 $v$ 到 $E$ 的距离最小化，即对于所有 $x \in E$，$\|v - w\| \leq \|v - x\|$。而且，如果对于某个 $x \in E$，$\|v - w\| = \|v - x\|$，则 $x = w$。

\textbf{证明}~ 设 $y = w - x$。那么 $v - x = v - w + w - x = v - w + y$。由于 $v - w \perp E$，所以 $y \perp v - w$，因此根据勾股定理 $\|v - x\|^2 = \|v - w\|^2 + \|y\|^2 \geq \|v - w\|^2$。注意，当且仅当 $y = 0$，即 $x = w$ 时，等号成立。

下面的命题表明，如果我们知道 $E$ 中的一个正交基，我们就能找到 $E$ 上的正交投影。

\textbf{命题 3.3。} 设 $\{v_1, v_2, \dots, v_r\}$ 是 $E$ 的一个正交基。那么向量 $v$ 到 $E$ 的正交投影 $P_E v$ 由以下公式给出：
$P_E v = \sum_{k=1}^r \alpha_k v_k$, 其中 $\alpha_k = \frac{(v, v_k)}{\|v_k\|^2}$。
换句话说，
(3.1) $P_E v = \sum_{k=1}^r \frac{(v, v_k)}{\|v_k\|^2} v_k$。
注意，$\alpha_k$ 的公式与 (2.1) 重合，即这个公式应用于一个正交系统（而不是基）可以得到其张成的子空间上的投影。

\textbf{3.3 的证明。} 设 $w := \sum_{k=1}^r \alpha_k v_k$, 其中 $\alpha_k = \frac{(v, v_k)}{\|v_k\|^2}$。我们想证明 $v - w \perp E$。根据引理 2.3，只要证明 $v - w \perp v_k$, $\forall k = 1, 2, \dots, n$ 即可。计算内积，我们得到对于 $k = 1, 2, \dots, r$:
$(v - w, v_k) = (v, v_k) - (w, v_k) = (v, v_k) - (\sum_{j=1}^r \alpha_j v_j, v_k) = (v, v_k) - \alpha_k (v_k, v_k) = (v, v_k) - \frac{(v, v_k)}{\|v_k\|^2} \|v_k\|^2 = 0$。

因此，如果我们知道 $E$ 中的一个正交基，我们就可以找到到 $E$ 的正交投影。特别地，由于任何只包含一个向量的系统都是正交系统，我们知道如何进行到一维空间的上的正交投影。但是如果我们只知道 $E$ 的一个基，我们该如何找到正交投影呢？幸运的是，存在一个简单的算法，可以从一个基得到一个正交基。

3.1. \textbf{格拉姆-施密特正交化算法。} 假设我们有一个线性无关系统 $\{x_1, x_2, \dots, x_n\}$。格拉姆-施密特方法从这个系统构造一个正交系统 $\{v_1, v_2, \dots, v_n\}$，使得 $\text{span}\{x_1, x_2, \dots, x_n\} = \text{span}\{v_1, v_2, \dots, v_n\}$。而且，对于所有 $r \leq n$，我们得到 $\text{span}\{x_1, x_2, \dots, x_r\} = \text{span}\{v_1, v_2, \dots, v_r\}$。
现在我们来描述这个算法。

\textbf{步骤 1。} 令 $v_1 := x_1$。记 $E_1 := \text{span}\{x_1\} = \text{span}\{v_1\}$。
\textbf{步骤 2。} 定义 $v_2$ 为
$v_2 = x_2 - P_{E_1} x_2 = x_2 - \frac{(x_2, v_1)}{\|v_1\|^2} v_1$。
定义 $E_2 = \text{span}\{v_1, v_2\}$。注意 $\text{span}\{x_1, x_2\} = E_2$。
\textbf{步骤 3。} 定义 $v_3$ 为
$v_3 := x_3 - P_{E_2} x_3 = x_3 - \frac{(x_3, v_1)}{\|v_1\|^2} v_1 - \frac{(x_3, v_2)}{\|v_2\|^2} v_2$。
令 $E_3 := \text{span}\{v_1, v_2, v_3\}$。注意 $\text{span}\{x_1, x_2, x_3\} = E_3$。还注意 $x_3 \notin E_2$ 所以 $v_3 \neq 0$。
...
\textbf{步骤 $r+1$。} 假设我们已经完成了过程的 $r$ 步，构造了一个正交系统（包含非零向量）$\{v_1, v_2, \dots, v_r\}$，使得 $E_r := \text{span}\{v_1, v_2, \dots, v_r\} = \text{span}\{x_1, x_2, \dots, x_r\}$。定义
$v_{r+1} := x_{r+1} - P_{E_r} x_{r+1} = x_{r+1} - \sum_{k=1}^r \frac{(x_{r+1}, v_k)}{\|v_k\|^2} v_k$。
注意 $x_{r+1} \notin E_r$ 所以 $v_{r+1} \neq 0$。
...
通过继续这个算法，我们将得到一个正交系统 $\{v_1, v_2, \dots, v_n\}$。

3.2. \textbf{一个例子。} 假设我们有向量 $x_1 = (1, 1, 1)^T$, $x_2 = (0, 1, 2)^T$, $x_3 = (1, 0, 2)^T$，我们想通过格拉姆-施密特来正交化它们。第一步定义 $v_1 = x_1 = (1, 1, 1)^T$。
第二步我们得到 $v_2 = x_2 - P_{E_1} x_2 = x_2 - \frac{(x_2, v_1)}{\|v_1\|^2} v_1$。
计算 $(x_2, v_1) = (\begin{pmatrix} 0 \\ 1 \\ 2 \end{pmatrix}, \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}) = 3$, $\|v_1\|^2 = 3$，我们得到
$v_2 = \begin{pmatrix} 0 \\ 1 \\ 2 \end{pmatrix} - \frac{3}{3} \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} -1 \\ 0 \\ 1 \end{pmatrix}$。
最后，定义 $v_3 = x_3 - P_{E_2} x_3 = x_3 - \frac{(x_3, v_1)}{\|v_1\|^2} v_1 - \frac{(x_3, v_2)}{\|v_2\|^2} v_2$。
计算 $(\begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix}, \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}) = 3$, $(\begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix}, \begin{pmatrix} -1 \\ 0 \\ 1 \end{pmatrix}) = 1$, $\|v_1\|^2 = 3$, $\|v_2\|^2 = 2$ ( $\|v_1\|^2$ 已经计算过了) 我们得到
$v_3 = \begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix} - \frac{3}{3} \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix} - \frac{1}{2} \begin{pmatrix} -1 \\ 0 \\ 1 \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix} - \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix} - \begin{pmatrix} -1/2 \\ 0 \\ 1/2 \end{pmatrix} = \begin{pmatrix} 1/2 \\ -1 \\ 1/2 \end{pmatrix}$。

\textbf{注释} ~由于乘以标量不改变正交性，因此可以乘以任意非零数来得到由格拉姆-施密特得到的向量 $v_k$。特别地，在许多理论构造中，人们通过将向量 $v_k$ 除以它们各自的范数 $\|v_k\|$ 来\textbf{归一化}它们。然后得到的结果系统将是标准正交的，并且公式会更简单。另一方面，在进行计算时，人们可能希望避免分数项，方法是将向量乘以其元素最小公分母的倒数。因此，人们可能希望将上面例子中的向量 $v_3$ 替换为 $(1, -2, 1)^T$。

3.3. \textbf{正交补。分解 $V = E \oplus E^\perp$。}
\textbf{定义}~ 对于子空间 $E$，其\textbf{正交补} $E^\perp$ 是所有与 $E$ 正交的向量的集合，$E^\perp := \{x : x \perp E\}$。
如果 $x, y \perp E$，则对于任意线性组合 $\alpha x + \beta y \perp E$（你能看出为什么吗？）。因此 $E^\perp$ 是一个子空间。根据正交投影的定义，任何内积空间 $V$ 中的向量都可以唯一地表示为 $v = v_1 + v_2$, $v_1 \in E$, $v_2 \perp E$（等价地，$v_2 \in E^\perp$）（其中显然 $v_1 = P_E v$）。这个陈述通常被象征性地写成 $V = E \oplus E^\perp$，这意味着任何向量都可以进行上述唯一的分解。以下命题给出了正交补的一个重要性质。

\textbf{命题 3.6。} 对于子空间 $E$，$(E^\perp)^\perp = E$。
证明留给读者作为练习，见下面的练习 3.12。

\textbf{练习}~

3.1. 将向量 $(1, 2, -2)^T$, $(1, -1, 4)^T$, $(2, 1, 1)^T$ 应用于格拉姆-施密特正交化。

3.2. 将向量 $(1, 2, 3)^T$, $(1, 3, 1)^T$ 应用于格拉姆-施密特正交化。写出到由这两个向量张成的二维子空间的\textbf{正交投影}矩阵。



3.3. 将上一个问题中得到的正交系统补全为 $\mathbb{R}^3$ 中的一个正交基，即向系统中添加一些向量（多少个？）以得到一个正交基。你能描述如何将一个正交系统补全为一般情况 $\mathbb{R}^n$ 或 $\mathbb{C}^n$ 中的一个正交基吗？

3.4. 求向量 $(2, 3, 1)^T$ 到由向量 $(1, 2, 3)^T$, $(1, 3, 1)^T$ 张成的子空间的距离。注意，我只要求计算到子空间的距离，而不是正交投影。

3.5. 找到向量 $(1, 1, 1, 1)^T$ 到由向量 $v_1 = (1, 3, 1, 1)^T$ 和 $v_2 = (2, -1, 1, 0)^T$ 张成的子空间的\textbf{正交投影}（注意 $v_1 \perp v_2$）。

3.6. 求向量 $(1, 2, 3, 4)^T$ 到由向量 $v_1 = (1, -1, 1, 0)^T$ 和 $v_2 = (1, 2, 1, 1)^T$ 张成的子空间的距离（注意 $v_1 \perp v_2$）。能否在不实际计算投影的情况下找到距离？这将简化计算。

3.7. 真或假：如果 $E$ 是 $V$ 的子空间，则 $\dim E + \dim(E^\perp) = \dim V$？证明你的结论。

3.8. 设 $P$ 是到子空间 $E$ 的正交投影，$\dim V = n$, $\dim E = r$。找出它的特征值和特征向量（特征子空间）。找出每个特征值的代数重数和几何重数。

3.9. （使用特征值计算行列式）。a) 求到由向量 $(1, 1, \dots, 1)^T$ 张成的一维子空间的\textbf{正交投影}矩阵；b) 设 $A$ 是一个主对角线全为 1，其他所有元素都为 1 的 $n \times n$ 矩阵。计算它的特征值和重数（使用上一个问题）；c) 计算矩阵 $A-I$（即主对角线全为零，其他所有元素都为 1 的矩阵）的特征值（和重数）；d) 计算 $\det(A-I)$。

3.10. （勒让德多项式）：设内积在多项式空间上由 $(f, g) = \int_{-1}^1 f(t)g(t)dt$ 定义。将格拉姆-施密特正交化应用于系统 $\{1, t, t^2, t^3\}$。勒让德多项式是所谓的正交多项式的特例，它们在数学的许多分支中起着重要作用。

3.11. 设 $P$ 是到子空间 $E$ 的正交投影。证明：
a) 矩阵 $P$ 是\textbf{自伴随}的，即 $P^* = P$。
b) $P^2 = P$。
\textbf{注：} 以上 2 个性质完全刻画了正交投影，即满足这些性质的任何矩阵都是某个正交投影的矩阵。我们稍后将讨论这一点。



3.12. 证明对于子空间 $E$，有 $(E^\perp)^\perp = E$。
\textbf{提示：} 很容易看出 $E$ 正交于 $E^\perp$（为什么？）。为了证明任何正交于 $E^\perp$ 的向量 $x$ 属于 $E$，使用上面第 3.3 节中的分解 $V = E \oplus E^\perp$。

3.13. 假设 $P$ 是到子空间 $E$ 的正交投影，而 $Q$ 是到其正交补 $E^\perp$ 的正交投影。
a) $P+Q$ 和 $PQ$ 是什么？
b) 证明 $P-Q$ 是它自己的逆。




正如第 2 章第 2 节所讨论的，方程 $Ax = b$ 有解当且仅当 $b \in \text{Ran } A$。但对于没有解的方程该怎么办？这似乎是一个愚蠢的问题，因为如果没有解，那么就没有解。但是，当我们要解一个没有解的方程时，情况可能会自然地出现，例如，如果我们从实验中得到了方程。如果我们没有错误，那么右侧 $b$ 属于列空间 $\text{Ran } A$，方程是相容的。但是在现实生活中，无法避免测量误差，所以一个理论上应该相容的方程可能没有解。那么，在这种情况下我们能做什么？

\section{最小二乘解} 

最简单的想法是写出误差 $\|Ax - b\|$ 并尝试找到最小化它的 $x$。如果我们能找到一个 $x$ 使得误差为 $0$，那么系统就是相容的，我们就得到了精确解。否则，我们就得到所谓的\textbf{最小二乘解}。\textbf{最小二乘}这个术语源于最小化 $\|Ax - b\|$ 等价于最小化 $\|Ax - b\|^2 = \sum_{k=1}^m |(Ax)_k - b_k|^2 = \sum_{k=1}^m |\sum_{j=1}^n A_{k,j} x_j - b_k|^2$，即最小化线性函数平方和。有几种方法可以找到最小二乘解。如果我们处于 $\mathbb{R}^n$ 中，并且所有内容都是实数，我们可以忽略绝对值。然后我们可以对每个变量 $x_j$ 取偏导数，并找到所有偏导数都为 $0$ 的地方，这将给我们最小值。

4.1.1. \textbf{几何方法。} 然而，有一个更简单的寻找最小值的方法。即，如果我们取所有可能的向量 $x$，那么 $Ax$ 会给出 $\text{Ran } A$ 中的所有可能向量，所以最小化 $\|Ax - b\|$ 就是从 $b$ 到 $\text{Ran } A$ 的距离。因此， $\|Ax - b\|$ 的值最小当且仅当 $Ax = P_{\text{Ran } A} b$，其中 $P_{\text{Ran } A}$ 表示到列空间 $\text{Ran } A$ 的正交投影。所以，为了找到最小二乘解，我们只需要解方程 $Ax = P_{\text{Ran } A} b$。

如果我们知道 $\text{Ran } A$ 中的一个正交基 $\{v_1, v_2, \dots, v_n\}$，我们可以通过公式 $P_{\text{Ran } A} b = \sum_{k=1}^n \frac{(b, v_k)}{\|v_k\|^2} v_k$ 来找到向量 $P_{\text{Ran } A} b$。如果我们只知道 $\text{Ran } A$ 中的一个基，我们需要使用格拉姆-施密特正交化来从它得到一个正交基。因此，理论上，问题已经解决了，但解决方案并不非常简单：它涉及格拉姆-施密特正交化，这在计算上可能很密集。幸运的是，存在一个更简单的解决方案。

4.1.2. \textbf{正规方程。} 即，$Ax$ 是正交投影 $P_{\text{Ran } A} b$ 当且仅当 $b - Ax \perp \text{Ran } A$（对所有 $x$，$Ax \in \text{Ran } A$）。如果 $a_1, a_2, \dots, a_n$ 是 $A$ 的列，那么条件 $A x \perp \text{Ran } A$ 可以重写为 $b - Ax \perp a_k$, $\forall k = 1, 2, \dots, n$。这意味着 $0 = (b - Ax, a_k) = a_k^*(b - Ax)$, $\forall k = 1, 2, \dots, n$。将行 $a_k^*$ 连接起来，我们得到这些方程等价于
$A^*(b - Ax) = 0$，
这反过来等价于所谓的\textbf{正规方程} $A^*Ax = A^*b$。该方程的解给出了 $Ax = b$ 的最小二乘解。注意，当且仅当 $A^*A$ 可逆时，最小二乘解是唯一的。

4.2. \textbf{正交投影公式。} 如上所述，如果 $x$ 是\textbf{正规方程} $A^*Ax = A^*b$ 的解（即 $Ax = b$ 的最小二乘解），那么 $Ax = P_{\text{Ran } A} b$。所以，为了找到 $b$ 到列空间 $\text{Ran } A$ 的正交投影，我们需要解正规方程 $A^*Ax = A^*b$，然后将解乘以 $A$。如果算子 $A^*A$ 可逆，则正规方程 $A^*Ax = A^*b$ 的解由 $x = (A^*A)^{-1}A^*b$ 给出，因此正交投影 $P_{\text{Ran } A} b$ 可以计算为 $P_{\text{Ran } A} b = A(A^*A)^{-1}A^*b$。由于这对所有 $b$ 都成立，
$P_{\text{Ran } A} = A(A^*A)^{-1}A^*$
是到 $\text{Ran } A$ 的正交投影矩阵的公式。




下面的定理意味着，对于一个 $m \times n$ 矩阵 $A$，矩阵 $A^*A$ 是可逆的当且仅当 $\text{rank } A = n$。

\textbf{定理 4.1。} 对于一个 $m \times n$ 矩阵 $A$，$\text{Ker } A = \text{Ker}(A^*A)$。
确实，根据秩定理，当且仅当 $\text{rank } A = n$ 时，$\text{Ker } A = \{0\}$。因此，当且仅当 $\text{rank } A = n$ 时，矩阵 $A^*A$ 是可逆的。我们把定理的证明留给读者。要证明 $\text{Ker } A = \text{Ker}(A^*A)$，需要证明两个包含关系 $\text{Ker}(A^*A) \subseteq \text{Ker } A$ 和 $\text{Ker } A \subseteq \text{Ker}(A^*A)$。其中一个包含关系是平凡的，对于另一个，使用 $\|Ax\|^2 = (Ax, Ax) = (A^*Ax, x)$ 的事实。

4.3. \textbf{一个例子：直线拟合。} 让我们引入几个最小二乘解自然出现的例子。假设我们知道两个量 $x$ 和 $y$ 之间的关系由线性规律 $y = a + bx$ 给出。系数 $a$ 和 $b$ 是未知的，我们希望通过实验数据找到它们。假设我们进行了 $n$ 次实验，得到了 $n$ 对 $(x_k, y_k)$，$k=1, 2, \dots, n$。理想情况下，所有点 $(x_k, y_k)$ 都应该在一条直线上，但由于测量误差，通常不会这样：点通常接近某条直线，但并不完全在上面。这时最小二乘解就有用了！理想情况下，系数 $a$ 和 $b$ 应该满足方程
$a + bx_k = y_k$, $k = 1, 2, \dots, n$
（注意这里，$x_k$ 和 $y_k$ 是一些固定的数字，而未知数是 $a$ 和 $b$）。如果可能找到这样的 $a$ 和 $b$，我们就有幸了。如果不行，标准做法是最小化总的二次误差 $\sum_{k=1}^n |a + bx_k - y_k|^2$。但是，最小化这个误差恰好是求解系统
$\begin{pmatrix} 1 & x_1 \\ 1 & x_2 \\ \vdots & \vdots \\ 1 & x_n \end{pmatrix} \begin{pmatrix} a \\ b \end{pmatrix} = \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix}$
的最小二乘解（未知数是 $a$ 和 $b$）。

4.3.1. \textbf{一个例子。} 假设我们的数据 $(x_k, y_k)$ 由对 $(−2, 4)$, $(−1, 2)$, $(0, 1)$, $(2, 1)$, $(3, 1)$ 组成。那么我们需要求解方程
$\begin{pmatrix} 1 & -2 \\ 1 & -1 \\ 1 & 0 \\ 1 & 2 \\ 1 & 3 \end{pmatrix} \begin{pmatrix} a \\ b \end{pmatrix} = \begin{pmatrix} 4 \\ 2 \\ 1 \\ 1 \\ 1 \end{pmatrix}$
的最小二乘解。
那么 $A^*A = \begin{pmatrix} 1 & 1 & 1 & 1 & 1 \\ -2 & -1 & 0 & 2 & 3 \end{pmatrix} \begin{pmatrix} 1 & -2 \\ 1 & -1 \\ 1 & 0 \\ 1 & 2 \\ 1 & 3 \end{pmatrix} = \begin{pmatrix} 5 & 2 \\ 2 & 18 \end{pmatrix}$，
并且 $A^*b = \begin{pmatrix} 1 & 1 & 1 & 1 & 1 \\ -2 & -1 & 0 & 2 & 3 \end{pmatrix} \begin{pmatrix} 4 \\ 2 \\ 1 \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 9 \\ -5 \end{pmatrix}$。
所以正规方程 $A^*Ax = A^*b$ 被重写为
$\begin{pmatrix} 5 & 2 \\ 2 & 18 \end{pmatrix} \begin{pmatrix} a \\ b \end{pmatrix} = \begin{pmatrix} 9 \\ -5 \end{pmatrix}$。
该方程的解是 $a = 2$, $b = -1/2$，因此最佳拟合直线是 $y = 2 - \frac{1}{2}x$。

4.4. \textbf{其他例子：曲线和平面拟合。} 最小二乘法不限于直线拟合。它也可以应用于更一般的曲线，以及更高维度中的曲面。这里唯一的限制是我们要寻找的参数必须以线性方式参与。一般算法如下：
1. 找到如果数据是精确拟合应该满足的方程；
2. 将这些方程写成一个线性系统，其中未知数是我们想要寻找的参数。注意，系统不一定是一致的（通常不是）；
3. 找到该系统的最小二乘解。

4.4.1. \textbf{曲线拟合示例。} 例如，假设我们知道 $x$ 和 $y$ 之间的关系由二次定律 $y = a + bx + cx^2$ 给出，所以我们想拟合一个抛物线 $y = a + bx + cx^2$ 到数据上。那么我们的未知数 $a, b, c$ 应该满足方程
$a + bx_k + cx_k^2 = y_k$, $k = 1, 2, \dots, n$
或者，以矩阵形式
$\begin{pmatrix} 1 & x_1 & x_1^2 \\ 1 & x_2 & x_2^2 \\ \vdots & \vdots & \vdots \\ 1 & x_n & x_n^2 \end{pmatrix} \begin{pmatrix} a \\ b \\ c \end{pmatrix} = \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix}$。
例如，对于上例中的数据，我们需要求解方程
$\begin{pmatrix} 1 & -2 & 4 \\ 1 & -1 & 1 \\ 1 & 0 & 0 \\ 1 & 2 & 4 \\ 1 & 3 & 9 \end{pmatrix} \begin{pmatrix} a \\ b \\ c \end{pmatrix} = \begin{pmatrix} 4 \\ 2 \\ 1 \\ 1 \\ 1 \end{pmatrix}$
的最小二乘解。
那么 $A^*A = \begin{pmatrix} 1 & 1 & 1 & 1 & 1 \\ -2 & -1 & 0 & 2 & 3 \\ 4 & 1 & 0 & 4 & 9 \end{pmatrix} \begin{pmatrix} 1 & -2 & 4 \\ 1 & -1 & 1 \\ 1 & 0 & 0 \\ 1 & 2 & 4 \\ 1 & 3 & 9 \end{pmatrix} = \begin{pmatrix} 5 & 2 & 18 \\ 2 & 18 & 26 \\ 18 & 26 & 114 \end{pmatrix}$，
并且 $A^*b = \begin{pmatrix} 1 & 1 & 1 & 1 & 1 \\ -2 & -1 & 0 & 2 & 3 \\ 4 & 1 & 0 & 4 & 9 \end{pmatrix} \begin{pmatrix} 4 \\ 2 \\ 1 \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 9 \\ -5 \\ 31 \end{pmatrix}$。
因此，正规方程 $A^*Ax = A^*b$ 是
$\begin{pmatrix} 5 & 2 & 18 \\ 2 & 18 & 26 \\ 18 & 26 & 114 \end{pmatrix} \begin{pmatrix} a \\ b \\ c \end{pmatrix} = \begin{pmatrix} 9 \\ -5 \\ 31 \end{pmatrix}$
它有一个唯一解 $a = 86/77$, $b = -62/77$, $c = 43/154$。因此，$y = \frac{86}{77} - \frac{62}{77}x + \frac{43}{154}x^2$ 是最佳拟合抛物线。

4.4.2. \textbf{平面拟合。} 再举一个例子，我们拟合一个平面 $z = a + bx + cy$ 到数据 $(x_k, y_k, z_k) \in \mathbb{R}^3$, $k=1, 2, \dots, n$。在精确拟合的情况下，我们应该有的方程是
$a + bx_k + cy_k = z_k$, $k=1, 2, \dots, n$,
或者，以矩阵形式
$\begin{pmatrix} 1 & x_1 & y_1 \\ 1 & x_2 & y_2 \\ \vdots & \vdots & \vdots \\ 1 & x_n & y_n \end{pmatrix} \begin{pmatrix} a \\ b \\ c \end{pmatrix} = \begin{pmatrix} z_1 \\ z_2 \\ \vdots \\ z_n \end{pmatrix}$。
所以，为了找到最佳拟合平面，我们需要找到这个系统（未知数是 $a, b, c$）的最小二乘解。

\textbf{练习}~

4.1. 求解方程组 $\begin{pmatrix} 1 & 0 \\ 0 & 1 \\ 1 & 1 \end{pmatrix} x = \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix}$ 的最小二乘解。

4.2. 找出矩阵 $\begin{pmatrix} 1 & 1 \\ 2 & -1 \\ -2 & 4 \end{pmatrix}$ 的列空间的\textbf{正交投影}矩阵 $P$。使用两种方法：格拉姆-施密特正交化和投影公式。比较结果。

4.3. 找到点 $(−2, 4), (−1, 3), (0, 1), (2, 0)$ 的最佳直线拟合（最小二乘解）。

4.4. 将平面 $z = a + bx + cy$ 拟合到四个点 $(1, 1, 3), (0, 3, 6), (2, 1, 5), (0, 0, 0)$。为此：
a) 找出 4 个关于 3 个未知数 $a, b, c$ 的方程，使得平面通过所有 4 个点（这个系统不一定有解）；
b) 找到该系统的最小二乘解。

4.5. \textbf{最小范数解。} 设方程 $Ax = b$ 有解，并且设 $A$ 有非平凡的核（因此解不唯一）。证明：
a) 存在唯一一个 $Ax = b$ 的解 $x_0$，它最小化范数 $\|x\|$，即存在唯一的 $x_0$ 使得 $Ax_0 = b$ 且 $\|x_0\| \leq \|x\|$ 对于任何满足 $Ax = b$ 的 $x$。
b) $x_0 = P_{(\text{Ker } A)^\perp} x$ 对于任何满足 $Ax = b$ 的 $x$。

4.6. \textbf{最小范数最小二乘解。} 将上一问题应用于方程 $Ax = P_{\text{Ran } A} b$，证明 $A x = b$ 的一个最小范数最小二乘解 $x_0$ 存在且唯一。
a) 存在唯一的最小二乘解 $x_0$ 最小化范数 $\|x\|$。
b) $x_0 = P_{(\text{Ker } A)^\perp} x$ 对于任何 $Ax = b$ 的最小二乘解 $x$。




\section{线性变换的伴随，基本子空间再次回顾}

5.1. \textbf{伴随矩阵与伴随算子。} 让我们回忆一下，对于一个 $m \times n$ 矩阵 $A$，其\textbf{共轭转置}（或简单地说\textbf{伴随}）$A^*$ 定义为 $A^* := \overline{A^T}$。换句话说，矩阵 $A^*$ 是通过转置矩阵 $A^T$ 然后取每个元素的复共轭得到的。以下恒等式是伴随矩阵的主要性质：$(Ax, y) = (x, A^*y)$ $\forall x \in \mathbb{C}^n, \forall y \in \mathbb{C}^m$。
在证明这个恒等式之前，让我们引入一些有用的公式。让我们回忆一下，对于转置矩阵我们有恒等式 $(AB)^T = B^T A^T$。由于对于复数 $z$ 和 $w$ 我们有 $\overline{zw} = \bar{z}\bar{w}$，所以对于伴随有恒等式 $(AB)^* = B^*A^*$。同样，由于 $(A^T)^T = A$ 且 $\overline{\bar{z}} = z$，$(A^*)^* = A$。
现在，我们准备证明主要恒等式：$(Ax, y) = y^*Ax = (A^*y)^*x = (x, A^*y)$；这里第一个和最后一个等式遵循内积在 $F^n$ 中的定义，而中间的等式遵循 $(A^*x)^* = x^*(A^*)^* = x^*A$ 的事实。

5.1.1. \textbf{伴随的唯一性。} 上述主要恒等式 $(Ax, y) = (x, A^*y)$ 通常用作伴随算子的定义。让我们首先注意到伴随算子是唯一的：如果一个矩阵 $B$ 满足 $(Ax, y) = (x, By)$ $\forall x, y$，则 $B = A^*$。确实，根据 $A^*$ 的定义，对于给定的 $y$，我们有 $(x, A^*y) = (x, By)$ $\forall x$，因此根据推论 1.5， $A^*y = By$。由于这对所有 $y$ 都成立，线性变换，因此矩阵 $A^*$ 和 $B$ 是相等的。




5.1.2. \textbf{抽象环境下的伴随变换。} 上述主要恒等式 $(Ax, y) = (x, A^*y)$ 可用于在抽象环境中定义伴随算子，其中 $A: V \to W$ 是作用在一个内积空间到另一个内积空间上的算子。即，我们定义 $A^*: W \to V$ 为满足 $(Ax, y) = (x, A^*y)$ $\forall x \in V, \forall y \in W$ 的算子。为什么这样的算子存在？我们可以简单地构造它：考虑 $V$ 中的一组标准正交基 $\{v_1, v_2, \dots, v_n\}$ 和 $W$ 中的一组标准正交基 $\{w_1, w_2, \dots, w_m\}$。如果 $[A]_{BA}$ 是这两个基下 $A$ 的矩阵，我们定义算子 $A^*$ 为定义其矩阵 $[A^*]_{AB} = ([A]_{BA})^*$。我们将该算子是伴随算子的证明留给读者作为练习。注意，上述第 5.1.1 节中的推理意味着伴随算子是唯一的。

5.1.3. \textbf{有用的公式。} 下面我们给出将广泛使用的伴随算子（矩阵）的性质。我们将证明留给读者作为练习。
1. $(A + B)^* = A^* + B^*$；
2. $(\alpha A)^* = \bar{\alpha} A^*$；
3. $(AB)^* = B^*A^*$；
4. $(A^*)^* = A$；
5. $(y, Ax) = (A^*y, x)$。

5.2. \textbf{基本子空间之间的关系。}
\textbf{定理 5.1。} 设 $A: V \to W$ 是作用在一个内积空间到另一个内积空间上的算子。那么
1. $\text{Ker } A^* = (\text{Ran } A)^\perp$；
2. $\text{Ker } A = (\text{Ran } A^*)^\perp$；
3. $\text{Ran } A = (\text{Ker } A^*)^\perp$；
4. $\text{Ran } A^* = (\text{Ker } A)^\perp$。

\textbf{注释} ~在第 2 章第 7 节，基本子空间被定义（如文献中常见的那样）使用 $A^T$ 而不是 $A^*$。当然，对于实数矩阵没有区别，所以在实数情况下，本定理给出了那里定义的基本子空间的几何描述。第 8 章下面第 3 节（定理 3.7）给出了使用 $A^T$ 定义的基本子空间的几何解释。本定理中的公式与定理 5.1 中的公式基本相同，只是解释略有不同。

\textbf{定理 5.1 的证明。} 首先，我们注意到，对于子空间 $E$，我们有 $(E^\perp)^\perp = E$，所以陈述 1 和 3 是等价的。类似地，出于同样的原因，陈述 2 和 4 也是等价的。最后，陈述 2 恰好是应用于算子 $A^*$ 的陈述 1（这里我们使用了 $(A^*)^* = A$ 的事实）。因此，我们只需要证明陈述 1。我们将为此陈述提供两种证明：“矩阵”证明和“不变”或“坐标无关”证明。在“矩阵”证明中，我们假设 $A$ 是一个 $m \times n$ 矩阵，即 $A: F^n \to F^m$。一般情况总可以通过选取 $V$ 和 $W$ 中的标准正交基来简化为这种情况。设 $a_1, a_2, \dots, a_n$ 是 $A$ 的列。注意，$x \in (\text{Ran } A)^\perp$ 当且仅当 $x \perp a_k$（即 $(x, a_k) = 0$）$\forall k = 1, 2, \dots, n$。根据 $F^n$ 中内积的定义，这意味着 $0 = (x, a_k) = a_k^* x$ $\forall k = 1, 2, \dots, n$。由于 $a_k^*$ 是 $A^*$ 的第 $k$ 行，上述 $n$ 个等式等价于方程 $A^*x = 0$。所以，我们证明了 $x \in (\text{Ran } A)^\perp$ 当且仅当 $A^*x = 0$，而这恰好是定理 1 的陈述。现在，让我们给出“坐标无关”的证明。$x \in (\text{Ran } A)^\perp$ 的含义是 $x$ 正交于所有形式为 $Ay$ 的向量，即 $(x, Ay) = 0$ $\forall y$。由于 $(x, Ay) = (A^*x, y)$，这个恒等式等价于 $(A^*x, y) = 0$ $\forall y$，并且根据引理 1.4，这当且仅当 $A^*x = 0$。所以我们证明了 $x \in (\text{Ran } A)^\perp$ 当且仅当 $A^*x = 0$，而这恰好是定理 1 的陈述。

5.3. \textbf{线性变换的“本质”部分。} 上述定理使得算子 $A$ 的结构以及基本子空间的几何学更加清晰。从该定理可以得出，算子 $A$ 可以表示为到 $\text{Ran } A^*$ 的正交投影与从 $\text{Ran } A^*$ 到 $\text{Ran } A$ 的同构的组合。
确实，设 $\tilde{A}: \text{Ran } A^* \to \text{Ran } A$ 是 $A$ 对定义域 $\text{Ran } A^*$ 和目标空间 $\text{Ran } A$ 的限制，$\tilde{A}x = Ax$, $\forall x \in \text{Ran } A^*$。由于 $\text{Ker } A = (\text{Ran } A^*)^\perp$，我们有 $Ax = AP_{\text{Ran } A^*}x = \tilde{A}P_{\text{Ran } A^*}x$ $\forall x \in X$；这里使用了 $x - P_{\text{Ran } A^*}x \in (\text{Ran } A^*)^\perp = \text{Ker } A$ 的事实。因此我们可以写成 $A = \tilde{A}P_{\text{Ran } A^*}$ $\forall x \in X$，（5.1）或者等价地说，$A = \tilde{A}P_{\text{Ran } A^*}$。还需注意，$\tilde{A}: \text{Ran } A^* \to \text{Ran } A$ 是一个可逆变换。首先我们注意到 $\text{Ker } \tilde{A} = \{0\}$：如果 $x \in \text{Ran } A^*$ 且 $\tilde{A}x = Ax = 0$，那么 $x \in \text{Ker } A = (\text{Ran } A^*)^\perp$，所以 $x \in \text{Ran } A^* \cap (\text{Ran } A^*)^\perp$，因此 $x = 0$。然后为了证明 $\tilde{A}$ 是满射的（surjective），必须确保 $\tilde{A}$ 是满射的。但这直接从 (5.1) 得出：$\text{Ran } \tilde{A} = \tilde{A}(\text{Ran } A^*) = A P_{\text{Ran } A^*} X = AX = \text{Ran } A$。同构 $\tilde{A}$ 有时被称为算子 $A$ 的“本质部分”（非标准术语）。“本质部分” $\tilde{A}: \text{Ran } A^* \to \text{Ran } A$ 是一个同构，这隐含了以下“复数”秩定理：$\text{rank } A = \text{rank } A^*$。但是，当然，这个定理也来自一个基本观察：复共轭不改变矩阵的秩，$\text{rank } A = \text{rank } \bar{A}$。

\textbf{练习}~

5.1. 证明对于方阵 $A$，$\det(A^*) = \det(A)$ 成立。

5.2. 找出矩阵 $A = \begin{pmatrix} 1 & 1 & 1 \\ 1 & 3 & 2 \\ 2 & 4 & 3 \end{pmatrix}$ 的所有四个基本子空间的\textbf{正交投影}矩阵。注意，实际上只需要计算其中两个投影。如果你选择合适的两个，其他的 2 个可以很容易地从它们得到（回想一下，投影到 $E$ 和 $E^\perp$ 的关系）。

5.3. 设 $A$ 是一个 $m \times n$ 矩阵。证明 $\text{Ker } A = \text{Ker}(A^*A)$。为此你需要证明两个包含关系 $\text{Ker}(A^*A) \subseteq \text{Ker } A$ 和 $\text{Ker } A \subseteq \text{Ker}(A^*A)$。其中一个包含关系是平凡的，对于另一个，使用 $\|Ax\|^2 = (Ax, Ax) = (A^*Ax, x)$ 的事实。

5.4. 使用 $\text{Ker } A = \text{Ker}(A^*A)$ 的等式来证明：
a) $\text{rank } A = \text{rank}(A^*A)$；
b) 如果 $Ax = 0$ 只有平凡解，则 $A$ 是左可逆的。（你只需要写出一个左逆的公式）。

5.5. 假设矩阵 $A$ 的 $A^*A$ 是可逆的，因此到 $\text{Ran } A$ 的正交投影由公式 $A(A^*A)^{-1}A^*$ 给出。你能写出到其他 3 个基本子空间（$\text{Ker } A$, $\text{Ker } A^*$, $\text{Ran } A^*$）的正交投影的公式吗？

5.6. 设矩阵 $P$ 是自伴随的 ($P^* = P$) 并且 $P^2 = P$。证明 $P$ 是一个正交投影的矩阵。
\textbf{提示：} 考虑分解 $x = x_1 + x_2$, $x_1 \in \text{Ran } P$, $x_2 \perp \text{Ran } P$，并证明 $Px_1 = x_1$, $Px_2 = 0$。对于其中一个等式，你将需要自伴随性，对于另一个等式，你需要 $P^2 = P$ 的性质。





6. 
\section{等距同构和酉算子~酉矩阵和正交矩阵}

6.1. \textbf{基本定义。}
\textbf{定义}~ 算子 $U: X \to Y$ 被称为\textbf{等距同构}，如果它保持范数，即 $\|Ux\| = \|x\|$ $\forall x \in X$。
以下定理表明等距同构保持内积：

\textbf{定理 6.1。} 算子 $U: X \to Y$ 是等距同构当且仅当它保持内积，即当且仅当 $(x, y) = (Ux, Uy)$ $\forall x, y \in X$。

\textbf{证明}~ 证明使用了极化恒等式（第 5 章引理 1.9）。例如，如果 $X$ 是复数空间（$U$ 是复数算子），$(Ux, Uy) = \frac{1}{4} \sum_{\alpha = \pm 1, \pm i} \alpha \|Ux + \alpha Uy\|^2 = \frac{1}{4} \sum_{\alpha = \pm 1, \pm i} \alpha \|U(x + \alpha y)\|^2 = \frac{1}{4} \sum_{\alpha = \pm 1, \pm i} \alpha \|x + \alpha y\|^2 = (x, y)$。
类似地，对于实数空间 $X$（$U$ 是实数算子），$(Ux, Uy) = \frac{1}{4} (\|Ux + Uy\|^2 - \|Ux - Uy\|^2) = \frac{1}{4} (\|U(x+y)\|^2 - \|U(x-y)\|^2) = \frac{1}{4} (\|x+y\|^2 - \|x-y\|^2) = (x, y)$。

\textbf{引理 6.2。} 算子 $U: X \to Y$ 是等距同构当且仅当 $U^*U = I$。

\textbf{证明}~ 如果 $U^*U = I$，那么根据伴随算子的定义，$(x, x) = (U^*Ux, x) = (Ux, Ux)$ $\forall x \in X$。因此 $\|x\| = \|Ux\|$，所以 $U$ 是等距同构。另一方面，如果 $U$ 是等距同构，那么根据伴随算子的定义和定理 6.1，对于所有 $x \in X$，$(U^*Ux, y) = (Ux, Uy) = (x, y)$ $\forall y \in X$，因此根据推论 1.5， $U^*Ux = x$。由于这对所有 $x \in X$ 都成立，所以 $U^*U = I$。

上面的引理意味着等距同构总是左可逆的（$U^*$ 是左逆）。

\textbf{定义}~ 等距同构 $U: X \to Y$ 被称为\textbf{酉}算子，如果它是可逆的。

\textbf{命题 6.3。} 等距同构 $U: X \to Y$ 是酉算子当且仅当 $\dim X = \dim Y$。

\textbf{证明}~ 由于 $U$ 是等距同构，它是左可逆的，并且由于 $\dim X = \dim Y$，它是可逆的（左可逆的方阵才是可逆的）。另一方面，如果 $U: X \to Y$ 是可逆的，那么 $\dim X = \dim Y$（只有方阵才是可逆的，同构的空间具有相等的维度）。

一个方阵 $U$ 被称为\textbf{酉}矩阵，如果 $U^*U = I$，即酉矩阵是作用在 $F^n$ 上的酉算子的矩阵。实数项的酉矩阵被称为\textbf{正交}矩阵。一个正交矩阵可以解释为作用在实数空间 $\mathbb{R}^n$ 上的酉算子的矩阵。

酉算子的几个性质：
1. 对于酉变换 $U$, $U^{-1} = U^*$；
2. 如果 $U$ 是酉的，那么 $U^* = U^{-1}$ 也必须是酉的；
3. 如果 $U$ 是等距同构，并且 $\{v_1, v_2, \dots, v_n\}$ 是一个标准正交基，那么 $\{Uv_1, Uv_2, \dots, Uv_n\}$ 是一个标准正交系统。而且，如果 $U$ 是酉的，$\{Uv_1, Uv_2, \dots, Uv_n\}$ 是一个标准正交基。
4. 酉算子的乘积也是酉算子。

6.2. \textbf{例子。} 首先，让我们注意到，一个矩阵 $U$ 是等距同构当且仅当它的列构成一个标准正交系统。通过计算乘积 $U^*U$ 可以很容易地检验这一点。可以很容易地检验出旋转矩阵 $\begin{pmatrix} \cos \alpha & -\sin \alpha \\ \sin \alpha & \cos \alpha \end{pmatrix}$ 的列彼此正交，并且每列的范数都为 1。因此，旋转矩阵是等距同构，并且由于它是方阵，所以它是酉的。由于旋转矩阵的所有元素都是实数，它是一个正交矩阵。下一个例子更抽象。
设 $X$ 和 $Y$ 是内积空间，$\dim X = \dim Y = n$，并且设 $\{x_1, x_2, \dots, x_n\}$ 和 $\{y_1, y_2, \dots, y_n\}$ 分别是 $X$ 和 $Y$ 中的标准正交基。定义一个算子 $U: X \to Y$ 为 $Ux_k = y_k$, $k = 1, 2, \dots, n$。由于对于向量 $x = \sum_{k=1}^n c_k x_k$, $\|x\|^2 = \sum_{k=1}^n |c_k|^2$ 和 $\|Ux\|^2 = \|\sum_{k=1}^n c_k y_k\|^2 = \sum_{k=1}^n |c_k|^2$，我们可以得出 $\|Ux\| = \|x\|$ $\forall x \in X$，所以 $U$ 是一个酉算子。

6.3. \textbf{酉算子的性质。}
\textbf{命题 6.4。} 设 $U$ 是一个酉矩阵。那么
1. $|\det U| = 1$。特别是，对于正交矩阵 $\det U = \pm 1$；
2. 如果 $\lambda$ 是 $U$ 的一个特征值，那么 $|\lambda| = 1$。

\textbf{注释} ~注意，对于正交矩阵，特征值（不像行列式）不一定必须是实数。我们老朋友，旋转矩阵就是一个例子。




\textbf{命题 6.4 的证明。} 设 $\det U = z$。由于 $\det(U^*) = \det(U)$，见问题 5.1，我们有 $|z|^2 = z\bar{z} = \det(U^*U) = \det I = 1$，所以 $|\det U| = |z| = 1$。陈述 1 证毕。为了证明陈述 2，我们注意到如果 $Ux = \lambda x$，那么 $\|Ux\| = \|\lambda x\| = |\lambda|\|x\|$，所以 $|\lambda| = 1$。

6.4. \textbf{酉等价算子。}
\textbf{定义}~ 算子（矩阵）$A$ 和 $B$ 被称为\textbf{酉等价}的，如果存在一个酉算子 $U$ 使得 $A = UBU^*$。由于对于酉 $U$ 我们有 $U^{-1} = U^*$，任何两个酉等价的矩阵也是相似的。反之则不然，很容易构造一对酉等价但不是酉等价的相似矩阵。下面的命题提供了一种构造反例的方法。

\textbf{命题 6.5。} 矩阵 $A$ 是酉等价于一个对角矩阵当且仅当它具有一个\textbf{正交}（或标准正交）的特征向量基。

\textbf{证明}~ 设 $A$ 与对角矩阵 $D$ 酉等价，即 $A = UDU^*$。设 $Bx = \lambda x$。那么 $AUx = UBU^*Ux = U Bx = U(\lambda x) = \lambda Ux$，即 $Ux$ 是 $A$ 的特征向量。所以，设 $A$ 具有由特征向量 $u_1, u_2, \dots, u_n$ 组成的\textbf{正交}基。通过将每个向量 $u_k$ 除以其范数（如果需要），我们可以假设系统 $\{u_1, u_2, \dots, u_n\}$ 是一个\textbf{标准正交}基。设 $D$ 是 $A$ 在基 $B = \{u_1, u_2, \dots, u_n\}$ 下的矩阵。显然，$D$ 是一个对角矩阵。设 $U$ 为以 $u_1, u_2, \dots, u_n$ 为列的矩阵。由于列向量构成了标准正交基， $U$ 是酉的。标准坐标变换公式意味着 $A = [A]_{SS} = [I]_{SB}[A]_{BB}[I]_{BS} = UDU^{-1}$，并且由于 $U$ 是酉的，$A = UDU^*$。



练习。

6.1. 对以下矩阵进行\textbf{正交对角化}，即对每个矩阵 $A$，找出酉矩阵 $U$ 和对角矩阵 $D$，使得 $A = UDU^*$：
$\begin{pmatrix} 1 & 2 \\ 2 & 1 \end{pmatrix}$, $\begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix}$, $\begin{pmatrix} 0 & 2 & 2 \\ 2 & 0 & 2 \\ 2 & 2 & 0 \end{pmatrix}$。

6.2. 真或假：一个矩阵是酉等价于一个对角矩阵当且仅当它具有一个\textbf{正交}的特征向量基。

6.3. 证明极化恒等式 $(Ax, y) = \frac{1}{4} [ (A(x+y), x+y) - (A(x-y), x-y) ]$（实数情况，$A=A^*$），以及 $(Ax, y) = \frac{1}{4} \sum_{\alpha = \pm 1, \pm i} \alpha (A(x+\alpha y), x+\alpha y)$（复数情况，$A$ 任意）。

6.4. 证明酉（正交）矩阵的乘积也是酉（正交）的。

6.5. 设 $U: X \to X$ 是一个有限维内积空间上的线性变换。真或假：
a) 如果 $\|Ux\| = \|x\|$ $\forall x \in X$，那么 $U$ 是酉的。
b) 如果 $\|Ue_k\| = \|e_k\|$, $k=1, 2, \dots, n$ 对于某个标准正交基 $\{e_1, e_2, \dots, e_n\}$，那么 $U$ 是酉的。
用证明或反例证明你的答案。

6.6. 设 $A$ 和 $B$ 是酉等价的 $n \times n$ 矩阵。
a) 证明 $\text{trace}(A^*A) = \text{trace}(B^*B)$。
b) 使用 a) 证明 $\sum_{j,k=1}^n |A_{j,k}|^2 = \sum_{j,k=1}^n |B_{j,k}|^2$。
c) 使用 b) 证明矩阵 $\begin{pmatrix} 1 & 2 \\ 2 & i \end{pmatrix}$ 和 $\begin{pmatrix} i & 4 \\ 1 & 1 \end{pmatrix}$ 不是酉等价的。

6.7. 以下哪些矩阵对是酉等价的：
a) $\begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}$ 和 $\begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}$。
b) $\begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}$ 和 $\begin{pmatrix} 0 & 1/2 \\ 1/2 & 0 \end{pmatrix}$。
c) $\begin{pmatrix} 0 & 1 & 0 \\ -1 & 0 & 0 \\ 0 & 0 & 1 \end{pmatrix}$ 和 $\begin{pmatrix} 2 & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & 0 \end{pmatrix}$。
d) $\begin{pmatrix} 0 & 1 & 0 \\ -1 & 0 & 0 \\ 0 & 0 & 1 \end{pmatrix}$ 和 $\begin{pmatrix} 1 & 0 & 0 \\ 0 & -i & 0 \\ 0 & 0 & i \end{pmatrix}$。
e) $\begin{pmatrix} 1 & 1 & 0 \\ 0 & 2 & 2 \\ 0 & 0 & 3 \end{pmatrix}$ 和 $\begin{pmatrix} 1 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 3 \end{pmatrix}$。
\textbf{提示：} 很容易排除不酉等价的矩阵：记住酉等价矩阵是相似的，而相似矩阵的迹、行列式和特征值是相同的。此外，一个矩阵是酉等价于一个对角矩阵当且仅当它具有一个特征向量的正交基。

6.8. 设 $U$ 是一个行列式为 1 的 $2 \times 2$ 正交矩阵。证明 $U$ 是一个旋转矩阵。

6.9. 设 $U$ 是一个行列式为 1 的 $3 \times 3$ 正交矩阵。证明：
a) $1$ 是 $U$ 的一个特征值。
b) 如果 $\{v_1, v_2, v_3\}$ 是一个标准正交基，使得 $Uv_1 = v_1$（记住 $1$ 是一个特征值），那么在基 $\{v_1, v_2, v_3\}$ 下 $U$ 的矩阵是 $\begin{pmatrix} 1 & 0 & 0 \\ 0 & \cos \alpha & -\sin \alpha \\ 0 & \sin \alpha & \cos \alpha \end{pmatrix}$，其中 $\alpha$ 是某个角度。
\textbf{提示：} 证明，由于 $v_1$ 是 $U$ 的特征向量，1 下方的所有元素必须为零，并且由于 $v_1$ 也是 $U^*$（为什么？）的特征向量，1 右侧的所有元素也必须为零。然后证明下方的 $2 \times 2$ 矩阵是一个行列式为 1 的正交矩阵，并使用上一问题。

7. 
\section{$\mathbb{R}^n$ 中的刚性运动}

$\mathbb{R}^n$ 中的一个\textbf{刚性运动}是一个变换 $f: V \to V$，它保持点之间的距离，即 $\|f(x) - f(y)\| = \|x - y\|$ $\forall x, y \in V$。
注意，定义中我们没有假设变换 $f$ 是线性的。显然，任何酉变换都是刚性运动。另一个刚性运动的例子是平移（移位）$a \in V$，$f(x) = x + a$。




下面的定理是主要结果，它表明任何实内积空间中的刚性运动都是正交变换和翻译的组合。

\textbf{定理 7.1。} 设 $f$ 是实内积空间 $X$ 中的一个刚性运动，设 $T(x) := f(x) - f(0)$。那么 $T$ 是一个正交变换。

为了证明这个定理，我们需要一个简单的引理。

\textbf{引理 7.2。} 设 $T$ 如定理 7.1 中所定义。那么对于所有 $x, y \in X$：
1. $\|Tx\| = \|x\|$；
2. $\|T(x) - T(y)\| = \|x - y\|$；
3. $(Tx, Ty) = (x, y)$。

\textbf{证明}~ 为了证明陈述 1，注意到 $\|T(x)\| = \|f(x) - f(0)\| = \|x - 0\| = \|x\|$。
陈述 2 源于以下恒等式链：$\|T(x) - T(y)\| = \|(f(x) - f(0)) - (f(y) - f(0))\| = \|f(x) - f(y)\| = \|x - y\|$。
另一种解释是 $T$ 是两个刚性运动的组合（先是 $f$，然后是平移 $-f(0)$），并且可以很容易地看出刚性运动的组合是刚性运动。由于 $T(0) = 0$，并且 $\|T(x)\| = \|T(x) - T(0)\|$，所以陈述 1 可以视为陈述 2 的一个特例。为了证明陈述 3，让我们注意到在实内积空间中
$\|T(x) - T(y)\|^2 = \|T(x)\|^2 + \|T(y)\|^2 - 2(T(x), T(y))$,
并且 $\|x - y\|^2 = \|x\|^2 + \|y\|^2 - 2(x, y)$。
回想一下 $\|T(x) - T(y)\| = \|x - y\|$ 并且 $\|T(x)\| = \|x\|$, $\|T(y)\| = \|y\|$，我们立即得到期望的结论。

\textbf{定理 7.1 的证明。} 首先，注意到对于所有 $x \in X$, $\|Tx\| = \|f(x) - f(0)\| = \|x - 0\| = \|x\|$，所以 $T$ 保持范数，$\|Tx\| = \|x\|$。我们想说 $T$ 是一个等距同构，但要能够说出这一点，我们需要证明 $T$ 是一个线性变换。为此，让我们在 $X$ 中固定一个标准正交基 $\{e_1, e_2, \dots, e_n\}$，并设 $b_k := T(e_k)$, $k=1, 2, \dots, n$。由于 $T$ 保持内积（引理 7.2 的陈述 3），我们可以得出 $\{b_1, b_2, \dots, b_n\}$ 是一个标准正交系统。事实上，由于 $\dim X = n$（因为基 $\{e_1, e_2, \dots, e_n\}$ 包含 $n$ 个向量），我们可以得出 $\{b_1, b_2, \dots, b_n\}$ 是一个标准正交\textbf{基}。设 $x = \sum_{k=1}^n \alpha_k e_k$。回忆一下根据抽象正交傅里叶分解 (2.2)，我们有 $\alpha_k = (x, e_k)$。将抽象正交傅里叶分解 (2.2) 应用于 $T(x)$ 和标准正交基 $\{b_1, b_2, \dots, b_n\}$，我们得到 $T(x) = \sum_{k=1}^n (T(x), b_k) b_k$。由于 $(T(x), b_k) = (T(x), T(e_k)) = (x, e_k) = \alpha_k$，我们得到 $T(\sum_{k=1}^n \alpha_k e_k) = \sum_{k=1}^n \alpha_k b_k$。这意味着 $T$ 是一个线性变换，其在基 $\{e_1, e_2, \dots, e_n\}$ 和 $\{b_1, b_2, \dots, b_n\}$ 下的矩阵是单位矩阵，$[T]_{B,S} = I$。另一种证明 $T$ 是线性变换的方法是进行以下直接计算：$\|T(x + \alpha y) - (T(x) + \alpha T(y))\|^2 = \|(T(x + \alpha y) - T(x)) - \alpha T(y)\|^2 = \|T(x + \alpha y) - T(x)\|^2 + \alpha^2 \|T(y)\|^2 - 2\alpha (T(x + \alpha y) - T(x), T(y)) = \|x + \alpha y - x\|^2 + \alpha^2\|y\|^2 - 2\alpha(T(x+\alpha y), T(y)) + 2\alpha(T(x), T(y)) = \|\alpha y\|^2 + \alpha^2\|y\|^2 - 2\alpha(x+\alpha y, y) + 2\alpha(x, y) = \alpha^2\|y\|^2 + \alpha^2\|y\|^2 - 2\alpha(x, y) - 2\alpha^2(y, y) + 2\alpha(x, y) = 2\alpha^2\|y\|^2 - 2\alpha^2\|y\|^2 = 0$。因此 $T(x+\alpha y) = T(x) + \alpha T(y)$，这意味着 $T$ 是线性的（取 $x=0$ 或 $\alpha=1$ 可得到线性变换定义的两个性质）。所以，$T$ 是一个满足 $\|Tx\| = \|x\|$ 的线性变换，即 $T$ 是一个等距同构。由于 $T: X \to X$， $T$ 是一个酉变换（见命题 6.3）。这完成了证明，因为一个正交变换仅仅是一个实内积空间中的酉变换。

\textbf{练习}~

7.1. 在 $\mathbb{C}^n$ 中给出一个刚性运动 $T$, $T(0)=0$，但 $T$ 不是线性变换。




8. 
\section{复化与反复化}
本节可能比本章的其余部分更抽象一些，可以首次阅读时跳过。

8.1. \textbf{反复化。}
8.1.1. \textbf{向量空间的复化。} 任何复数向量空间都可以解释为一个实向量空间：我们只需要忘记我们可以乘以复数，并且只允许乘以实数。例如，空间 $\mathbb{C}^n$ \textbf{典型地}被识别为实向量空间 $\mathbb{R}^{2n}$：每个复数坐标 $z_k = x_k + iy_k$ 给出两个实坐标 $x_k$ 和 $y_k$。“典型地”在这里意味着这是一种标准、最自然地识别 $\mathbb{C}^n$ 和 $\mathbb{R}^{2n}$ 的方式。注意，虽然上述定义给了我们一种从复数坐标得到实数坐标的典型方法，但它并没有说明坐标的排序。事实上，有两种标准的方法来排序坐标 $x_k, y_k$。一种方法是先取实部，然后取虚部，所以排序是 $x_1, x_2, \dots, x_n, y_1, y_2, \dots, y_n$。另一种标准选择是排序 $x_1, y_1, x_2, y_2, \dots, x_n, y_n$。本节的内容不依赖于坐标的排序选择，所以读者不必担心选择排序。

8.1.2. \textbf{内积的复化。} 结果表明，如果我们有一个复内积（在一个复数空间中），我们可以以典型的方式从中得到一个实内积：实际上，你可能已经在不知不觉中做过了。即，考虑 $\mathbb{C}^n$ 的上述例子，它典型地被识别为 $\mathbb{R}^{2n}$。设 $(x, y)_{\mathbb{C}}$ 表示 $\mathbb{C}^n$ 中的标准内积，$(x, y)_{\mathbb{R}}$ 表示 $\mathbb{R}^{2n}$ 中的标准内积（注意 $\mathbb{R}^n$ 中的标准内积不依赖于坐标的排序）。那么（见下面的练习 8.1）
$(x, y)_{\mathbb{R}} = \text{Re}((x, y)_{\mathbb{C}})$ (8.1)
这个公式可以用于典型地从复内积中定义一个实内积，在一般情况下也是如此。即，很容易检查出，如果 $(x, y)_{\mathbb{C}}$ 是一个复内积空间中的内积，那么 $(x, y)_{\mathbb{R}}$ 定义为 (8.1) 是一个实内积（在其相应的实空间上）。总结一下，我们可以说，要对一个复内积空间进行反复化，我们只需“忘记”我们可以乘以复数，即我们只允许乘以实数。被反复化空间中的典型实内积由公式 (8.1) 给出。

\textbf{注释} ~任何（复数）线性变换作用在 $\mathbb{C}^n$ 上（或更广泛地说，在复向量空间上）都会产生一个实线性变换：这仅仅是因为如果 $T(\alpha x + \beta y) = \alpha T x + \beta T y$ 对 $\alpha, \beta \in \mathbb{C}$ 成立，那么它当然对 $\alpha, \beta \in \mathbb{R}$ 也成立。反之则不成立，即作用在 $\mathbb{C}^n$ 的反复化 $\mathbb{R}^{2n}$ 上的（实数）线性变换并不总是产生 $\mathbb{C}^n$ 的（复数）线性变换（在抽象情况下也是一样）。例如，如果考虑 $n=1$ 的情况，那么乘以一个复数 $z$（复数空间 $\mathbb{C}^1$ 中的线性变换的一般形式）被视为 $\mathbb{R}^2$ 中的线性变换时，具有一个非常特殊的结构（你能描述它吗？）。

8.2. \textbf{复化。} 我们也可以做相反的事情，即从一个实空间得到一个复空间：实际上，你可能已经做过了，而没有太在意。即，给定一个实内积空间 $\mathbb{R}^n$，我们可以从它得到一个复空间 $\mathbb{C}^n$，方法是允许复数坐标（在两种情况下都使用标准内积）。在这种情况下，空间 $\mathbb{R}^n$ 将是 $\mathbb{C}^n$ 的一个\textbf{实子空间}，由具有实数坐标的向量组成。抽象地说，这个构造可以描述如下：给定一个实向量空间 $X$，我们可以将其复化 $X_{\mathbb{C}}$ 定义为所有对 $[x_1, x_2]$, $x_1, x_2 \in X$ 的集合，其中加法和实数 $\alpha$ 的乘法是逐坐标定义的：$[x_1, x_2] + [y_1, y_2] = [x_1 + y_1, x_2 + y_2]$, $\alpha [x_1, x_2] = [\alpha x_1, \alpha x_2]$。如果 $X = \mathbb{R}^n$，那么向量 $x_1$ 由 $\mathbb{C}^n$ 中复数坐标的实部组成，向量 $x_2$ 由虚部组成。因此，非正式地说，我们可以将对 $[x_1, x_2]$ 写成 $x_1 + ix_2$。为了定义复数乘法，我们定义 $i$ 的乘法为 $i[x_1, x_2] = [-x_2, x_1]$（将 $[x_1, x_2]$ 写成 $x_1 + ix_2$ 时，我们可以看到它必须这样定义），并使用第二个分配律 $\alpha(v+w) = \alpha v + \alpha w$ 来定义任意复数的乘法。如果 $X$ 是一个内积空间，我们还可以将内积扩展到 $X_{\mathbb{C}}$：
$([x_1, x_2], [y_1, y_2])_{X_{\mathbb{C}}} = (x_1, y_1)_X + (x_2, y_2)_X$。
要看到一切都定义良好，最简单的方法是固定一个基（在实内积空间的情况下是标准正交基），然后查看坐标表示下会发生什么。然后我们可以看到，如果我们把向量 $x_1$ 看作由复数坐标的实部组成的向量，把向量 $x_2$ 看作由坐标的虚部组成的向量，那么这个构造恰好是 $\mathbb{R}^n$ 的标准复化（通过允许复数坐标）正如上面描述的那样。我们可以用坐标无关的方式来解释这个构造，而不必选取基并处理坐标，这意味着结果不依赖于基的选择。所以，思考复化的最简单方法可能是这样的：要构造一个实向量空间 $X$ 的复化，我们可以选取一个基（如果 $X$ 是实内积空间，则选取一个标准正交基），然后处理坐标，允许复数坐标。结果空间不依赖于基的选择；我们可以通过标准的坐标变换公式从一个坐标集得到另一个。注意，任何实空间 $X$ 中的线性变换 $T$ 都会产生其复化 $X_{\mathbb{C}}$ 中的一个线性变换 $T_{\mathbb{C}}$。看到这一点最简单的方法是固定 $X$ 中的一个基（如果 $X$ 是实内积空间，则选取一个标准正交基），并以坐标表示进行处理：在这种情况下，$T_{\mathbb{C}}$ 与 $T$ 具有相同的矩阵。在抽象表示中，我们可以写成 $T_{\mathbb{C}}[x_1, x_2] = [Tx_1, Tx_2]$。另一方面，并非所有 $X_{\mathbb{C}}$ 中的线性变换都可以从 $X$ 中的变换得到；如果我们进行坐标复化，只有具有实数矩阵的变换才有效。请注意，这与第 8.1 节中描述的反复化的情景完全相反。一个细心的读者可能已经注意到，复化和反复化的操作不是彼此的逆。首先，空间及其复化具有相同的维度，而一个 $n$ 维空间的复化其维度为 $2n$。此外，正如我们刚才讨论的，实数和复数线性变换之间的关系在这些情况下是完全相反的。在下一节中，我们将讨论一个操作，在某种意义上是反复化的逆。

8.3. \textbf{向实数空间引入复数结构。} 本节介绍的构造仅适用于偶数维的实数空间。
8.3.1. \textbf{引入复数结构的初等方法。} 设 $X$ 是一个 $2n$ 维的实内积空间。我们想通过引入 $X$ 上的复数结构来逆转反复化过程，即识别这个空间与一个复数空间，使其反复化（见第 8.1 节）得到原始空间 $X$。最简单的想法是固定 $X$ 中的一个标准正交基，然后将该基下的坐标分成两半。我们然后将一半坐标（例如，坐标 $x_1, x_2, \dots, x_n$）视为复数坐标的实部，并将其余部分视为虚部。然后我们需要将实部和虚部组合起来：例如，如果我们处理 $x_1, x_2, \dots, x_n$ 作为实部，$x_{n+1}, x_{n+2}, \dots, x_{2n}$ 作为虚部，我们可以定义复数坐标 $z_k = x_k + ix_{n+k}$。当然，结果通常取决于标准正交基的选择，以及我们如何分割实数坐标为实部和虚部，以及如何将它们组合起来。从第 8.1 节描述的反复化构造也可以看出，所有实内积空间 $X$ 上的复数结构都可以通过这种方式获得。
8.3.2. \textbf{从初等到抽象构造复数结构。} 上述构造可以用抽象的、坐标无关的方式来描述。即，设我们将空间 $X$ 分解为 $X = E \oplus E^\perp$，其中 $E$ 是一个子空间，$\dim E = n$（因此 $\dim E^\perp = n$），并且设 $U_0: E \to E^\perp$ 是一个酉（更确切地说，是正交的，因为我们的空间是实数的）变换。注意，如果 $\{v_1, v_2, \dots, v_n\}$ 是 $E$ 中的一个标准正交基，那么系统 $\{U_0 v_1, U_0 v_2, \dots, U_0 v_n\}$ 是 $E^\perp$ 中的一个标准正交基，因此 $\{v_1, v_2, \dots, v_n, U_0 v_1, U_0 v_2, \dots, U_0 v_n\}$ 是整个空间 $X$ 中的一个标准正交基。如果 $x_1, x_2, \dots, x_{2n}$ 是该基下向量 $x$ 的坐标，并且我们将 $x_k + ix_{n+k}$, $k=1, 2, \dots, n$ 作为 $x$ 的复数坐标，那么 $i$ 的乘法由正交变换 $U$ 表示，该变换在子空间 $E, E^\perp$ 的正交基下由块对角矩阵 $U = \begin{pmatrix} 0 & -U_0^* \\ U_0 & 0 \end{pmatrix}$ 给出。这意味着 $i \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = U \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 0 & -U_0^* \\ U_0 & 0 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix}$，$x_1 \in E$, $x_2 \in E^\perp$。显然，$U$ 是一个正交变换，且 $U^2 = -I$。因此，任何实内积空间 $X$ 上的复数结构都由满足 $U^2 = -I$ 的正交变换 $U$ 给出；变换 $U$ 赋予了我们虚数单位 $i$ 的乘法。




$i x = U x$, 那么复数乘法必须定义为 $( \alpha + \beta i ) x := \alpha x + \beta U x = (\alpha I + \beta U) x$, $\alpha, \beta \in \mathbb{R}$, $x \in X$。(8.2)
我们将使用这个公式来定义复数乘法。不难检查出，对于由 (8.2) 定义的复数乘法，所有复向量空间的公理都得到了满足。例如，可以通过利用实空间 $X$ 中的线性并注意到，关于代数运算（加法和乘法），形式为 $\alpha I + \beta U$ 的线性变换的行为方式与复数 $\alpha + \beta i$ 完全相同，即这样的变换给了我们复数域的一个\textbf{表示}。这意味着首先，形式为 $\alpha I + \beta U$ 的变换的和与积是相同形式的变换，并且为了得到结果的系数 $\alpha, \beta$，我们可以对相应的复数执行运算并取结果的实部和虚部。注意，这里我们需要 $U^2 = -I$ 的恒等式，但我们不需要 $U$ 是正交变换的事实。因此，我们得到了一个复向量空间的结构。为了得到一个复\textbf{内积}空间，我们需要引入一个复内积，使得原始实内积是它的实部。我们在这里确实没有其他选择：注意到对于复内积 $\text{Im}(x, y) = \text{Re}[-i(x, y)_{\mathbb{R}}] = \text{Re}((x, i y)_{\mathbb{R}})$，我们发现定义复内积的唯一方法是
$(x, y)_{\mathbb{C}} := (x, y)_{\mathbb{R}} + i(x, Uy)_{\mathbb{R}}$。(8.3)

我们来证明这是一个内积。我们需要 $U^* = -U$ 的事实，见下面的练习 8.4（这里的 $U^*$ 是指相对于原始实内积的伴随）。为了证明 $(y, x)_{\mathbb{C}} = (x, y)_{\mathbb{C}}$，我们使用恒等式 $U^* = -U$ 和实内积的对称性：$(y, x)_{\mathbb{C}} = (y, x)_{\mathbb{R}} + i(y, Ux)_{\mathbb{C}} = (x, y)_{\mathbb{R}} + i(Ux, y)_{\mathbb{R}} = (x, y)_{\mathbb{R}} - i(x, Uy)_{\mathbb{R}} = (x, y)_{\mathbb{R}} + i(x, Uy)_{\mathbb{R}} = (x, y)_{\mathbb{C}}$。为了证明复内积的线性性，让我们首先注意到 $(x, y)_{\mathbb{C}}$ 在第一个（实际上是每个）参数上是\textbf{实线性}的，即对于 $\alpha, \beta \in \mathbb{R}$，$( \alpha x + \beta y, z )_{\mathbb{C}} = \alpha (x, z)_{\mathbb{C}} + \beta (y, z)_{\mathbb{C}}$；这是正确的，因为右侧的每个加数在参数上都是实线性的。使用 $(x, y)_{\mathbb{C}}$ 的实线性以及 $U^* = -U$（这意味着 $(Ux, y)_{\mathbb{R}} = -(x, Uy)_{\mathbb{R}}$）以及 $U$ 的正交性，我们得到以下等式链：$(\alpha I + \beta U)x, y)_{\mathbb{C}} = (\alpha x, y)_{\mathbb{C}} + \beta (Ux, y)_{\mathbb{C}} = \alpha (x, y)_{\mathbb{C}} + \beta [(Ux, y)_{\mathbb{R}} + i(Ux, Uy)_{\mathbb{R}}] = \alpha (x, y)_{\mathbb{C}} + \beta [-(x, Uy)_{\mathbb{R}} + i(x, y)_{\mathbb{R}}] = \alpha (x, y)_{\mathbb{C}} + \beta i [(x, y)_{\mathbb{R}} + i(x, Uy)_{\mathbb{R}}] = \alpha (x, y)_{\mathbb{C}} + \beta i (x, y)_{\mathbb{C}} = (\alpha + \beta i)(x, y)_{\mathbb{C}}$，这证明了\textbf{复}线性。最后，为了证明 $(x, x)_{\mathbb{C}}$ 的非负性，让我们注意到（见练习 8.3）$(x, Ux)_{\mathbb{R}} = 0$，所以 $(x, x)_{\mathbb{C}} = (x, x)_{\mathbb{R}} = \|x\|^2 \geq 0$。

8.3. \textbf{从初等到抽象构造复数结构。} 对于不习惯如此“高明”和抽象的证明的读者，还有另一种更实际的解释。即，可以证明（见练习 8.5），存在一个子空间 $E$，$\dim E = n$（回想一下 $\dim X = 2n$），使得在分解 $X = E \oplus E^\perp$ 下 $U$ 的矩阵由块对角矩阵 $U = \begin{pmatrix} 0 & -U_0^* \\ U_0 & 0 \end{pmatrix}$ 给出，其中 $U_0: E \to E^\perp$ 是某个正交变换。



设 $\{v_1, v_2, \dots, v_n\}$ 是 $E$ 中的一个标准正交基。那么 $\{U_0 v_1, U_0 v_2, \dots, U_0 v_n\}$ 是 $E^\perp$ 中的一个标准正交基，所以 $\{v_1, v_2, \dots, v_n, U_0 v_1, U_0 v_2, \dots, U_0 v_n\}$ 是整个空间 $X$ 中的一个标准正交基。考虑该基下的坐标 $x_1, x_2, \dots, x_{2n}$，并将 $x_k + ix_{n+k}$, $k=1, 2, \dots, n$ 作为 $x$ 的复数坐标，那么 $i$ 的乘法由变换 $U$ 来表示：它对于 $x \in E$ 是平凡的，对于 $y \in E^\perp$ 也是平凡的，因此它对于所有实数线性组合 $\alpha x + \beta y$ 都成立，即对于 $X$ 中的所有向量都成立。但这意味着抽象复数结构的引入以及相应的初等方法给出了相同的结果！而且，由于初等方法清楚地给出复数结构，抽象方法也给出了相同的复数结构。

\textbf{练习}~

8.1. 证明公式 (8.1)。即，证明如果 $x = (z_1, z_2, \dots, z_n)^T$, $y = (w_1, w_2, \dots, w_n)^T$, $z_k = x_k + iy_k$, $w_k = u_k + iv_k$, $x_k, y_k, u_k, v_k \in \mathbb{R}$，那么 $\text{Re}(\sum_{k=1}^n z_k \bar{w}_k) = \sum_{k=1}^n x_k u_k + \sum_{k=1}^n y_k v_k$。

8.2. 证明如果 $(x, y)_{\mathbb{C}}$ 是复内积空间中的内积，那么 $(x, y)_{\mathbb{R}}$ 由 (8.1) 定义的是一个实内积空间。

8.3. 设 $U$ 是一个满足 $U^2 = -I$ 的正交变换（在实内积空间 $X$ 中）。证明对于所有 $x \in X$， $Ux \perp x$。

8.4. 证明，如果 $U$ 是一个满足 $U^2 = -I$ 的正交变换，那么 $U^* = -U$。

8.5. 设 $U$ 是一个满足 $U^2 = -I$ 的实内积空间中的正交变换。证明在这种情况下 $\dim X = 2n$，并且存在一个子空间 $E \subset X$，$\dim E = n$，以及一个正交变换 $U_0: E \to E^\perp$，使得在 $X = E \oplus E^\perp$ 的分解下，$U$ 由块对角矩阵 $U = \begin{pmatrix} 0 & -U_0^* \\ U_0 & 0 \end{pmatrix}$ 给出。这个陈述可以很容易地从第 6 章定理 5.1 得到，如果我们注意到 $\mathbb{R}^2$ 中的唯一满足 $R_\alpha^2 = -I$ 的旋转是角度为 $\pm \pi/2$ 的旋转。但是，可以找到一个初等的证明，而无需使用该定理。例如，该陈述在 $\dim X = 2$ 时是平凡的：在这种情况下，我们可以选择任何一维子空间作为 $E$，见练习 8.3。




然后，不难证明，这样的变换 $U$ 不存在于 $\mathbb{R}^2$ 中，并且我们可以通过归纳 $\dim X$ 来完成证明。



