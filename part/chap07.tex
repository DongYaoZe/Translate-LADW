

\chapter{第七章~~双线性型与二次型}


尽管研究\textbf{实}二次型（即二次齐次多项式）可能是本章主题的最初动机，但\textbf{复}二次型（$A \xx, \xx)$, $\xx \in \CC^n$, $A = A^*$）也具有重要的意义。因此，除非另有说明，结果和计算在实数和复数情况下都适用。

为了避免重复书写本质上相同的公式，我们使用适应复数情况的记号：特别是，在实数情况下，用 $A^*$ 代替 $A^T$.~

\section{1. 主要定义}

\subsection{1.1. $\RR^n$ 上的双线性型}

$\RR^n$ 上的双线性型是一个有两个参数 $\xx, \yy \in \RR^n$ 的函数 $L = L(\xx, \yy)$，它在每个参数上都是线性的，即满足：

1. $L(\alpha \xx_1 + \beta \xx_2, \yy) = \alpha L(\xx_1, \yy) + \beta L(\xx_2, \yy)$；

2. $L(\xx, \alpha \yy_1 + \beta \yy_2) = \alpha L(\xx, \yy_1) + \beta L(\xx, \yy_2)$.~

双线性型的值可以属于任意向量空间，但在本书中，我们只考虑取实数值的向量。

如果 $\xx = (x_1, x_2, \dots, x_n)^T$ 且 $\yy = (y_1, y_2, \dots, y_n)^T$，则双线性型可以写成
$$L(\xx, \yy) = \sum_{j,k=1}^n a_{j,k} x_k y_j,$$
或者以矩阵形式表示为
$$L(\xx, \yy) = (A \xx, \yy),$$
其中
$$A = \begin{pmatrix} a_{1,1} & a_{1,2} & \dots & a_{1,n} \\ a_{2,1} & a_{2,2} & \dots & a_{2,n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n,1} & a_{n,2} & \dots & a_{n,n} \end{pmatrix}.$$
矩阵 $A$ 由双线性型 $L$ 唯一确定。

\subsection{1.2. $\RR^n$ 上的二次型}

二次型有几种等价的定义。

可以认为二次型是双线性型 $L$ 的“对角线”，即任何二次型 $Q$ 由 $Q[\xx] = L(\xx, \xx) = (A\xx, \xx)$ 定义。

另一种更代数的方式是，二次型是一个\textbf{二次齐次多项式}，即 $Q[\xx]$ 是一个关于 $n$ 个变量 $x_1, x_2, \dots, x_n$ 的多项式，只包含二次项。这意味着只允许出现 $ax_k^2$ 和 $cx_j x_k$ 形式的项。

可以将二次型 $Q[\xx]$ 写成 $Q[\xx] = (A\xx, \xx)$ 的方式有很多（事实上是无限多种）。例如，二次型 $Q[\xx] = x_1^2 + x_2^2 - 4x_1x_2$ 在 $\RR^2$ 上可以表示为 $(A\xx, \xx)$，其中 $A$ 可以是以下任何一个矩阵：

$$\begin{pmatrix} 1 & -4 \\ 0 & 1 \end{pmatrix}, \quad \begin{pmatrix} 1 & 0 \\ -4 & 1 \end{pmatrix}, \quad \begin{pmatrix} 1 & -2 \\ -2 & 1 \end{pmatrix}.$$
事实上，任何形式为 $$\begin{pmatrix} 1 & a \\ -4-a & 1 \end{pmatrix}$$
的矩阵都可以。

但是，如果我们要求矩阵 $A$ 是对称的，那么这样的矩阵是唯一的：

\fbox{\begin{minipage}{0.9\textwidth}
$\RR^n$ 上的任何二次型 $Q[\xx]$ 都存在唯一的表示 $Q[\xx] = (A\xx, \xx)$，其中 $A$ 是一个（实）对称矩阵。
\end{minipage}}

例如，对于二次型 
$$Q[\xx] = x_1^2 + 3x_2^2 + 5x_3^2 + 4x_1x_2 - 16x_1x_3 + 7x_2x_3$$
在 $\RR^3$ 上，对应的对称矩阵 $A$ 是
$$A = \begin{pmatrix} 1 & 2 & -8 \\ 2 & 3 & 3.5 \\ -8 & 3.5 & 5 \end{pmatrix}.$$

\subsection{1.3. $\CC^n$ 上的二次型}

也可以在 $\CC^n$（或任何复内积空间）上定义一个\textbf{二次型}，通过取一个自伴算子 $A = A^*$，并定义 $Q$ 为 $Q[\xx] = (A\xx, \xx)$.~虽然我们的主要例子将是 $\RR^n$，但所有定理在 $\CC^n$ 的设置下也成立。考虑到这一点，我们将始终使用 $A^*$ 而不是 $A^T$.~

与实数情况的唯一本质区别是，在复数情况下我们没有选择的自由：如果二次型是实数，则对应的矩阵必须是埃尔米特的（自伴随的）。

注意到如果 $A = A^*$，那么 $$(A\xx, \xx) = (\xx, A^*\xx) = (\xx, A\xx) = \overline{(A\xx, \xx)},$$
所以 $(A\xx, \xx) \in \RR$.~

其逆命题也成立。

\textbf{引理 1.1}~~

设 $(A\xx, \xx)$ 对所有 $\xx \in \CC^n$ 都是实数。那么 $A = A^*$.~

我们把证明留给读者作为练习，见下面的问题 1.4。

证明引理 1.1 的一种可能方法是使用下面版本的极化恒等式。

\textbf{引理 1.2}

设 $A$ 是内积空间 $X$ 中的一个算子。

1. 如果 $X$ 是一个复空间，则对于任意 $\xx, \yy \in X$，
$$(A\xx, \yy) = \frac{1}{4} \sum_{\alpha \in \CC : \alpha^4=1} \alpha(A(\xx + \alpha \yy), \xx + \alpha \yy).$$

2. 如果 $X$ 是一个实空间且 $A = A^*$，则对于任意 $\xx, \yy \in X$，
$$(A\xx, \yy) = \frac{1}{4} [(A(\xx + \yy), \xx + \yy) - (A(\xx - \yy), \xx - \yy)].$$

引理 1.2 的证明请参见上面第 5 章的练习 6.3。

\begin{exer} \textbf{练习}~~

1.1. 求 $\RR^3$ 上双线性型 $L$ 的矩阵，其中 $$L(\xx, \yy) = x_1y_1 + 2x_1y_2 + 14x_1y_3 - 5x_2y_1 + 2x_2y_2 - 3x_2y_3 + 8x_3y_1 + 19x_3y_2 - 2x_3y_3.$$

1.2. 通过 $$L(\xx, \yy) = \det[\xx, \yy]$$ 在 $\RR^2$ 上定义双线性型 $L$（即，计算 $L(\xx, \yy)$ 时，我们构造一个以 $\xx, \yy$ 为列的 $2 \times 2$ 矩阵并计算其行列式）。

求 $L$ 的矩阵。

1.3. 求 $\RR^3$ 上二次型 $Q$ 的矩阵，其中 $$Q[\xx] = x_1^2 + 2x_1x_2 - 3x_1x_3 - 9x_2^2 + 6x_2x_3 + 13x_3^2.$$

1.4. 证明上面的引理 1.1。

\textbf{提示}：考虑表达式 $(A(\xx + z\yy), \xx + z\yy)$，并证明如果它对所有 $z \in \CC$ 都是实数，那么 $(A\xx, \yy) = \overline{(\yy, A^*\xx)}$.~\end{exer}

\section{2. 二次型的对角化}

你可能之前在研究平面上的二次曲线时遇到过二次型。也许你甚至研究过 $\RR^3$ 中的二次曲面。

我们想为这些对象的分类提供一个统一的方法。假设我们有一个在 $\RR^n$ 中的集合，由方程 $Q[\xx] = 1$ 定义，其中 $Q$ 是某个二次型。
如果 $Q$ 具有某种简单的形式，例如，如果其对应的矩阵是对角矩阵，即如果 $Q[\xx] = a_1x_1^2 + a_2x_2^2 + \dots + a_nx_n^2$，那么我们可以很容易地可视化这个集合，特别是当 $n=2, 3$ 时。在更高的维度中，即使不能可视化，也能很好地理解集合的结构。

因此，如果我们给定一个一般、复杂的二次型，我们想尽可能地简化它，例如，使其对角化。
实现这一目标的标准方法是变量替换。

\subsection{2.1. 正交对角化}

设我们有一个在 $\FF^n$（$\FF$ 是 $\RR$ 或 $\CC$）中的二次型 $Q[\xx] = (A\xx, \xx)$.~引入新的变量 $\yy = (y_1, y_2, \dots, y_n)^T \in \FF^n$，其中 $\yy = S^{-1}\xx$，这里 $S$ 是某个可逆的 $n \times n$ 矩阵，所以 $\xx = S\yy$.~

那么，
$$Q[\xx] = Q[S\yy] = (AS\yy, S\yy) = (S^*AS\yy, \yy).$$
所以，在新变量 $\yy$ 下，二次型具有矩阵 $S^*AS$.~

因此，我们想找到一个可逆矩阵 $S$，使得矩阵 $S^*AS$ 是对角矩阵。
注意，这与我们之前讨论的矩阵对角化是不同的：我们试图将矩阵 $A$ 表示为 $A = SDS^{-1}$，所以对角矩阵 $D = S^{-1}AS$.~然而，对于酉矩阵 $U$，我们有 $U^* = U^{-1}$，我们可以正交对角化对称矩阵。因此，我们可以将之前研究的\textbf{正交对角化}应用于二次型。

具体来说，我们可以将矩阵 $A$ 表示为 $A = UDU^* = UDU^{-1}$.~回想一下，$D$ 是一个对角矩阵，对角线上的元素是 $A$ 的特征值，而 $U$ 是特征向量构成的矩阵（我们需要选择一个正交的特征向量基）。那么 $D = U^*AU$，所以在新变量 $\yy = U^{-1}\xx$ 下，二次型具有对角矩阵。

让我们分析一下正交对角化的几何意义。酉矩阵 $U$ 的列 $\uu_1, \uu_2, \dots, \uu_n$ 构成了 $\FF^n$ 中的一个标准正交基，称之为基 $\B$.~从这个基到标准基的坐标变换矩阵 $[I]_{\SSS,\B}$ 正好是 $U$.~我们知道 $\yy = (y_1, y_2, \dots, y_n)^T = U^{-1}\xx$，所以坐标 $y_1, y_2, \dots, y_n$ 可以解释为向量 $\xx$ 在新基 $\uu_1, \uu_2, \dots, \uu_n$ 下的坐标。

因此，正交对角化允许我们非常清晰地可视化集合 $Q[\xx] = 1$，或者类似的集合，只要我们能对对角矩阵可视化。

\textbf{例子}~~

考虑一个二次变量的二次型（即 $\RR^2$ 上的二次型），$Q(x, y) = 2x^2 + 2y^2 + 2xy$.~让我们描述满足 $Q(x, y) = 1$ 的点 $(x, y)^T \in \RR^2$ 的集合。

$Q$ 的矩阵是
$$A = \begin{pmatrix} 2 & 1 \\ 1 & 2 \end{pmatrix}.$$
对该矩阵进行正交对角化，我们可以将其表示为
$$A = U \begin{pmatrix} 3 & 0 \\ 0 & 1 \end{pmatrix} U^*,\quad\text{其中}\quad U = \frac{1}{\sqrt{2}} \begin{pmatrix} 1 & -1 \\ 1 & 1 \end{pmatrix},$$
或者等价地 $$U^*AU = \begin{pmatrix} 3 & 0 \\ 0 & 1 \end{pmatrix} =: D.$$
集合 $\{\yy : (D\yy, \yy) = 1\}$ 是半轴为 $1/\sqrt{3}$ 和 $1$ 的椭圆。因此，集合 $\{\xx \in \RR^2 : (A\xx, \xx) = 1\}$ 是同一个椭圆，只是在新基 $(\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}})^T$, $(-\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}})^T$ 下，或者说，是旋转了 $\pi/4$ 的同一个椭圆。

\subsection{2.2. 非正交对角化}

正交对角化涉及到计算特征值和特征向量，所以对于大的 $n$ 可能难以用计算机完成。另一方面，非正交对角化，即找到一个可逆矩阵 $S$（不要求 $S^{-1} = S^*$）使得 $D = S^*AS$ 是对角矩阵，计算起来要容易得多，并且只需要代数运算（加、减、乘、除）。

下面我们介绍两种最常用的非正交对角化方法。

\subsubsection{2.2.1. 通过配方法对角化}

第一种方法基于配方法。我们将以实二次型（$\RR^n$ 上的二次型）为例来说明这种方法。经过简单的修改，这种方法也可以用于复数情况，但我们在此不作讨论。如有必要，感兴趣的读者应能自行进行适当的修改。

再次考虑一个二次变量的二次型，$Q[\xx] = 2x_1^2 + 2x_1x_2 + 2x_2^2$（与上面例子中的二次型相同，只是这里我们称变量为 $x_1, x_2$ 而不是 $x, y$）。
由于 
$$2(x_1 + \frac{1}{2}x_2)^2 = 2(x_1^2 + 2x_1 \frac{1}{2}x_2 + \frac{1}{4}x_2^2) = 2x_1^2 + 2x_1x_2 + \frac{1}{2}x_2^2$$（注意，前两项与 $Q$ 的前两项重合），我们得到
$$2x_1^2 + 2x_1x_2 + 2x_2^2 = 2(x_1 + \frac{1}{2}x_2)^2 + \frac{3}{2}x_2^2 = 2y_1^2 + \frac{3}{2}y_2^2,$$
其中 $y_1 = x_1 + \frac{1}{2}x_2$ 且 $y_2 = x_2$.~

同样的方法可以应用于多于 2 个变量的二次型。例如，考虑 $\RR^3$ 中的二次型 $Q[\xx]$：
$$Q[\xx] = x_1^2 - 6x_1x_2 + 4x_1x_3 - 6x_2x_3 + 8x_2^2 - 3x_3^2.$$
考虑所有涉及第一个变量 $x_1$ 的项（本例中为前三项），我们提取一个包含这些项（加上其他项）的完全平方或其倍数。

由于 $$(x_1 - 3x_2 + 2x_3)^2 = x_1^2 - 6x_1x_2 + 4x_1x_3 - 12x_2x_3 + 9x_2^2 + 4x_3^2,$$
我们可以将二次型重写为
$$(x_1 - 3x_2 + 2x_3)^2 - x_2^2 + 6x_2x_3 - 7x_3^2.$$
注意，表达式 $-x_2^2 + 6x_2x_3 - 7x_3^2$ 只包含变量 $x_2$ 和 $x_3$.~
由于 
$$-(x_2 - 3x_3)^2 = -(x_2^2 - 6x_2x_3 + 9x_3^2) = -x_2^2 + 6x_2x_3 - 9x_3^2,$$
我们有
$$-x_2^2 + 6x_2x_3 - 7x_3^2 = -(x_2 - 3x_3)^2 + 2x_3^2.$$
因此，我们可以将二次型 $Q$ 写成
$$Q[\xx] = (x_1 - 3x_2 + 2x_3)^2 - (x_2 - 3x_3)^2 + 2x_3^2 = y_1^2 - y_2^2 + 2y_3^2,$$
其中 $$y_1 = x_1 - 3x_2 + 2x_3,\quad y_2 = x_2 - 3x_3,\quad y_3 = x_3.$$

最后，让我们来解决一个细心的读者可能已经提出的问题：如果我们某个时候得到了两个变量的乘积，但没有相应的平方项，该怎么办？例如，如何对角化形式 $x_1x_2$？答案直接来自恒等式
$$(2.1)\quad 4x_1x_2 = (x_1 + x_2)^2 - (x_1 - x_2)^2,$$
这给出了表示
$$Q[\xx] = y_1^2 - y_2^2,\quad y_1 = (x_1 + x_2)/2,~y_2 = (x_1 - x_2)/2.$$

\subsubsection{2.2.2. 使用行/列运算进行对角化}

还有另一种对二次型进行非正交对角化的方法。其思想是对二次型的矩阵 $A$ 进行行运算。与高斯-若尔当消元法的区别在于，在每次行运算后，我们需要执行相同的列运算，原因是我们想得到对角矩阵 $S^*AS$.~

我们以一个例子来说明一切是如何工作的。假设我们要对角化一个矩阵为
$$A = \begin{pmatrix} 1 & -1 & 3 \\ -1 & 2 & 1 \\ 3 & 1 & 1 \end{pmatrix}$$
的二次型。我们将矩阵 $A$ 与单位矩阵进行扩充，并对增广矩阵 $(A | I)$ 执行行/列运算。在每次行运算后，我们必须对矩阵 $A$ 执行相同的列运算。
\begin{equation} \notag
\begin{split}
\begin{pmatrix} 1 & -1 & 3 & | & 1 & 0 & 0 \\ -1 & 2 & 1 & | & 0 & 1 & 0 \\ 3 & 1 & 1 & | & 0 & 0 & 1 \end{pmatrix} \xrightarrow{R_2+R_1} 
&\ \begin{pmatrix} 1 & -1 & 3 & | & 1 & 0 & 0 \\ 0 & 1 & 4 & | & 1 & 1 & 0 \\ 3 & 1 & 1 & | & 0 & 0 & 1 \end{pmatrix} \xrightarrow{} \\
\begin{pmatrix} 1 & 0 & 3 & | & 1 & 0 & 0 \\ 0 & 1 & 4 & | & 1 & 1 & 0 \\ 3 & 4 & 1 & | & 0 & 0 & 1 \end{pmatrix} \xrightarrow{R_3-3R_1} 
&\ \begin{pmatrix} 1 & 0 & 3 & | & 1 & 0 & 0 \\ 0 & 1 & 4 & | & 1 & 1 & 0 \\ 0 & 4 & -8 & | & -3 & 0 & 1 \end{pmatrix} \xrightarrow{}\\
\begin{pmatrix} 1 & 0 & 0 & | & 1 & 0 & 0 \\ 0 & 1 & 4 & | & 1 & 1 & 0 \\ 0 & 4 & -8 & | & -3 & 0 & 1 \end{pmatrix} \xrightarrow{R_3-4R_2}
&\ \begin{pmatrix} 1 & 0 & 0 & | & 1 & 0 & 0 \\ 0 & 1 & 4 & | & 1 & 1 & 0 \\ 0 & 0 & -24 & | & -7 & -4 & 1 \end{pmatrix} \xrightarrow{}\\
\begin{pmatrix} 1 & 0 & 0 & | & 1 & 0 & 0 \\ 0 & 1 & 0 & | & 1 & 1 & 0 \\ 0 & 0 & -24 & | & -7 & -4 & 1 \end{pmatrix}
\end{split}\end{equation}
注意，我们只对增广矩阵的左侧执行列运算。

我们得到左侧的对角矩阵 $D$，右侧的矩阵 $S^*$，所以 $D = S^*AS$.~
$$\begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & -24 \end{pmatrix} = 
\begin{pmatrix} 1 & 0 & 0 \\ 1 & 1 & 0 \\ -7 & -4 & 1 \end{pmatrix}
\begin{pmatrix} 1 & -1 & 3 \\ -1 & 2 & 1 \\ 3 & 1 & 1 \end{pmatrix}
\begin{pmatrix} 1 & 1 & 7 \\ 0 & 1 & -4 \\ 0 & 0 & 1 \end{pmatrix}.
$$
让我解释一下这个方法为何有效。行运算是通过左乘一个基本矩阵实现的。对应的列运算是通过右乘其转置的基本矩阵实现的。因此，执行行运算 $E_1, E_2, \dots, E_N$ 和相同的列运算，我们将矩阵 $A$ 转换为
$$(2.2)\quad E_N \dots E_2 E_1 A E_1^* E_2^* \dots E_N^* = EAE^*.$$
至于右侧的单位矩阵，我们只对其执行了行运算，所以单位矩阵变为
$$E_N \dots E_2 E_1 I = EI = E.$$
如果我们现在设 $E^* = S$，则我们得到 $S^*AS$ 是一个对角矩阵，而矩阵 $E = S^*$ 是变换后的增广矩阵的右半部分。

在上面的例子中，我们很幸运，因为我们不需要交换两行。这个操作稍微棘手一些。如果你知道该怎么做，它会很简单，但可能很难猜到正确的行运算。例如，考虑一个矩阵为
$$A = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}$$
的二次型。如果我们想通过行和列运算来对角化它，最简单的想法是交换第 1 行和第 2 行。但我们也必须执行相同的列运算，即交换第 1 列和第 2 列，所以我们会得到相同的矩阵。因此，我们需要一些更不寻常的操作。例如，恒等式（2.1）可以用来对角化这个二次型。

然而，一个更简单的想法也奏效：使用行运算来得到对角线上的非零项！例如，如果我们开始使 $a_{1,1}$ 非零，下面的连续行（及相应的列）运算是一种可能的选择：
\begin{equation} \notag
\begin{split}
\begin{pmatrix} 0 & 1 & | & 1 & 0 \\ 1 & 0 & | & 0 & 1 \end{pmatrix} \xrightarrow{R_1+ \frac{1}{2}R_2} 
&\ \begin{pmatrix} 1/2 & 1 & | & 1 & 1/2 \\ 1 & 0 & | & 0 & 1 \end{pmatrix} \xrightarrow{} \\
\begin{pmatrix} 1 & 1 & | & 1 & 1/2 \\ 1 & 0 & | & 0 & 1 \end{pmatrix} \xrightarrow{R_2-R_1} 
&\ \begin{pmatrix} 1 & 1 & | & 1 & 1/2 \\ 0 & -1 & | & -1 & 1/2 \end{pmatrix}\xrightarrow{}\\
\begin{pmatrix} 1 & 0 & | & 1 & 1/2 \\ 0 & -1 & | & -1 & 1/2 \end{pmatrix}
\end{split}\end{equation}

\textbf{注记}~~

非正交对角化在一个非正交基下提供了对集合 $Q[\xx] = 1$ 的简单描述。它比正交对角化给出的表示更难可视化。然而，如果我们不关心细节，例如，如果我们只需要知道该集合是椭圆（或双曲面等），那么非正交对角化是获得答案的更简单方法。

\textbf{注记 2.1}~~
对于复数二次型（即形式为 $(A\xx, \xx)$, $A = A^*$），非正交对角化与实数情况的工作方式相同，唯一的区别是相应的“列运算”具有共轭复数系数。

原因是，如果一个行运算是通过左乘一个基本矩阵 $E_k$ 给出的，那么相应的列运算是通过右乘 $E_k^*$ 给出的，见（2.2）。

注意到公式（2.2）在复数和实数情况下都适用：在实数情况下，我们可以写 $E_k^T$ 而不是 $E_k^*$，但使用埃尔米特伴随允许我们在两种情况下使用相同的公式。

\begin{exer} \textbf{练习}~~

2.1. 对矩阵 $$A = \begin{pmatrix} 1 & 2 & 1 \\ 2 & 3 & 2 \\ 1 & 2 & 1 \end{pmatrix}.$$ 的二次型进行对角化。使用两种方法：配方法和行运算。你更喜欢哪一种？

你能判断矩阵 $A$ 是否是正定的吗？

2.2. 对于矩阵 $$A = \begin{pmatrix} 2 & 1 & 1 \\ 1 & 2 & 1 \\ 1 & 1 & 2 \end{pmatrix},$$
正交对角化相应的二次型，即找到一个对角矩阵 $D$ 和一个酉矩阵 $U$，使得 $D = U^*AU$.~\end{exer}

\section{3. 惯性定律}

如上所述，对角化二次型有许多方法。注意，最终的对角矩阵不是唯一的。例如，如果我们得到一个对角矩阵 $$D = \text{diag}\{\lambda_1, \lambda_2, \dots, \lambda_n\},$$
我们可以取一个对角矩阵 
$$S = \text{diag}\{s_1, s_2, \dots, s_n\},\quad s_k \in \RR,\quad s_k \ne 0,$$
并将 $D$ 变换为 $$S^*DS = \text{diag}\{s_1^2\lambda_1, s_2^2\lambda_2, \dots, s_n^2\lambda_n\}.$$
这种变换改变了 $D$ 的对角线元素。然而，它\textbf{不改变}对角线元素的\textbf{符号}。这始终是成立的！

也就是说，著名的\textbf{惯性定律}(Sylvester’s Law of Inertia)指出：

\fbox{\begin{minipage}{0.9\textwidth}
对于一个埃尔米特矩阵 $A$（即二次型 $Q[\xx] = (A\xx, \xx)$）及其任意对角化 $D = S^*AS$，对 $D$ 的正（负、零）对角线元素的数量仅取决于 $A$，而不取决于对角化的具体选择。
\end{minipage}}

这里我们当然假设 $S$ 是一个可逆矩阵，$D$ 是一个对角矩阵。

惯性定律证明的思路是，用与 $S$ 或 $D$ 无关的 $A$ 来表达对角化 $D = S^*AS$ 的正（负、零）对角线元素的数量。

我们将需要以下定义。

\textbf{定义}~~

给定一个 $n \times n$ 埃尔米特矩阵 $A = A^*$（$\FF^n$ 上的二次型 $Q[\xx] = (A\xx, \xx)$），我们将一个子空间 $E \subset \FF^n$ 称为\textbf{正的}（分别\textbf{负的}，分别\textbf{零的}），如果对所有 $\xx \in E, \xx \ne 0$，都有 
$$(A\xx, \xx) > 0\quad (\text{分别} ~(A\xx, \xx) < 0,\quad \text{分别}~ (A\xx, \xx) = 0.)$$

有时，为了强调 $A$ 的作用，我们会说 $A$-正（$A$-负，$A$-零）。

\textbf{定理 3.1}~~

设 $A$ 是一个 $n \times n$ 埃尔米特矩阵， $D = S^*AS$ 是它的对角化（通过可逆矩阵 $S$）。那么 $D$ 的正（分别负）对角线元素的数量等于 $A$-正（分别 $A$-负）子空间的最大维度。

上面的定理说明，如果 $r_+$ 是 $D$ 的正对角线元素的数量，那么存在一个维度为 $r_+$ 的 $A$-正子空间 $E$，但是不可能找到一个维度大于 $r_+$ 的正子空间 $E$.~

我们将需要以下引理，它可以被视为上述定理的一个特例。

\textbf{引理 3.2}~~

设 $D$ 是一个对角矩阵 $D = \text{diag}\{\lambda_1, \lambda_2, \dots, \lambda_n\}$.~那么 $D$ 的正（分别负）对角线元素的数量等于 $D$-正（分别 $D$-负）子空间的最大维度。

\textbf{证明}~~

通过重新排列 $\FF^n$ 中的标准基（改变编号），我们可以无损地假设正对角线元素是前 $r_+$ 个对角线元素。

考虑由前 $r_+$ 个坐标向量 $\ee_1, \ee_2, \dots, \ee_{r_+}$ 张成的子空间 $E_+$.~显然 $E_+$ 是一个 $D$-正子空间，且 $\dim E_+ = r_+$.~

现在我们证明对于任何其他的 $D$-正子空间 $E$，都有 $\dim E \le r_+$.~
考虑正交投影 $P = P_{E_+}$，
$$P \xx = (x_1, x_2, \dots, x_{r_+}, 0, \dots, 0)^T,\quad \xx = (x_1, x_2, \dots, x_n)^T.$$
对于一个 $D$-正子空间 $E$，定义一个算子 $T: E \to E_+$ 为 $$T \xx = P \xx,\quad \forall \xx \in E.$$

换句话说，$T$ 是投影 $P$ 的\textbf{限制}(restriction)（$P$ 定义在整个空间上，但我们将它的定义域限制到 $E$，目标空间限制到 $E_+$）。我们得到一个从 $E$ 到 $E_+$ 的算子，并使用另一个字母来区分它与 $P$.~

注意到 $\ker T = \{\oo\}$.~确实，设 $\xx = (x_1, x_2, \dots, x_n)^T \in E$ 且 $T \xx = P \xx = \oo$.~那么，根据 $P$ 的定义，
$$x_1 = x_2 = \dots = x_{r_+} = 0.$$
因此 
$$(D\xx, \xx) = \sum_{k=r_++1}^n \lambda_k x_k^2 \le 0\quad(\lambda_k \le 0 ~\text{对}~k > r_+).$$
但是 $\xx$ 属于一个 $D$-正子空间 $E$，所以不等式 $(D\xx, \xx) \le 0$ 仅对 $\xx=\oo$ 成立。

现在我们应用秩定理（第 2 章定理 7.1）。首先，$\text{rank } T = \dim \text{Ran } T \le \dim E_+ = r_+$，因为 $\text{Ran } T \subset E_+$.~根据秩定理，$\dim \ker T + \text{rank } T = \dim E$.~但是我们刚刚证明了 $\ker T = \{\oo\}$，即 $\dim \ker T = 0$，所以 $$\dim E = \text{rank } T \le \dim E_+ = r_+.$$

为了证明关于负对角线元素的命题，我们只需对矩阵 $-D$ 应用上述推理。

\textbf{定理 3.1 的证明}~~

设 $D = S^*AS$ 是 $A$ 的一个对角化。由于 
$$(D\xx, \xx) = (S^*AS\xx, \xx) = (AS\xx, S\xx),$$
可知对于任何 $D$-正子空间 $E$，子空间 $SE$ 是一个 $A$-正子空间。同样的恒等式暗示，对于任何 $A$-正子空间 $F$，子空间 $S^{-1}F$ 是 $D$-正的。

由于 $S$ 和 $S^{-1}$ 是可逆变换，$\dim E = \dim SE$ 且 $\dim F = \dim S^{-1}F$.~因此，对于任何 $D$-正子空间 $E$，我们可以找到一个相同维度的 $A$-正子空间（即 $SE$），反之亦然：对于任何 $A$-正子空间 $F$，我们可以找到一个相同维度的 $D$-正子空间（即 $S^{-1}F$）。
因此，$A$-正子空间和 $D$-正子空间的最大维度是相同的，定理得证。

关于负对角线元素的处理方式类似，细节留作读者练习。

\section{4. 正定二次型~~极小极大特征值刻画与塞尔维斯特正定性判据}

\textbf{定义}~~

一个二次型 $Q$ 被称为
\begin{itemize}
\item \textbf{正定}，如果对所有 $\xx \ne \oo$，有 $Q[\xx] > 0$.~
\item \textbf{半正定}，如果对所有 $\xx$，有 $Q[\xx] \ge 0$.~
\item \textbf{负定}，如果对所有 $\xx \ne \oo$，有 $Q[\xx] < 0$.~
\item \textbf{半负定}，如果对所有$\xx$，有 $Q[\xx] \le 0$.~
\item \textbf{不定}，如果它取正值和负值，即存在向量 $x_1$ 和 $x_2$ 使得 $Q[x_1] > 0$ 且 $Q[x_2] < 0$.~
\end{itemize}

\textbf{定义}~~

一个埃尔米特矩阵 $A = A^*$ 被称为是\textbf{正定}（负定，……）的，如果相应的二次型 $Q[\xx] = (A\xx, \xx)$ 是正定（负定，……）的。

\textbf{定理 4.1}~~

设 $A = A^*$.~那么

1. $A$ 是正定的，当且仅当 $A$ 的所有特征值都是正的。

2. $A$ 是半正定的，当且仅当 $A$ 的所有特征值都是非负的。

3. $A$ 是负定的，当且仅当 $A$ 的所有特征值都是负的。

4. $A$ 是半负定的，当且仅当 $A$ 的所有特征值都是非正的。

5. $A$ 是不定的，当且仅当它同时具有正特征值和负特征值。

\textbf{证明}~~

证明可以平凡地从正交对角化得出。事实上，存在一个标准正交基，使得 $A$ 在该基下的矩阵是对角矩阵，而对于对角矩阵，定理是显而易见的。

\textbf{注记}~~

注意到，为了判断一个矩阵（二次型）是否是正定的（负定的等），不必计算特征值。根据惯性定律，只需执行任意的（不一定是正交的）对角化 $D = S^*AS$，然后查看 $D$ 的对角线元素。

\subsection{4.1. 塞尔维斯特正定性判据}
很容易看出，一个 $2 \times 2$ 矩阵 
$$A = \begin{pmatrix} a & b \\ \bar{b} & c \end{pmatrix}$$
是正定的，当且仅当

$$(4.1)\quad a > 0\quad\text{且} \quad\det A = ac - |b|^2 > 0.$$ 

事实上，如果 $a > 0$ 且 $\det A = ac - |b|^2 > 0$，那么 $c > 0$，所以 $\text{trace } A = a+c > 0$.~因此，我们知道如果 $\lambda_1, \lambda_2$ 是 $A$ 的特征值，那么 $\lambda_1\lambda_2 > 0$ ($\det A > 0$) 且 $\lambda_1 + \lambda_2 = \text{trace } A > 0$.~这只有可能在两个特征值都为正时发生。因此，我们证明了条件（4.1）蕴含 $A$ 是正定的。反向蕴含很简单，留作读者练习。

这个结果可以推广到 $n \times n$ 矩阵。也就是说，对于矩阵 
$$A = \begin{pmatrix} a_{1,1} & a_{1,2} & \dots & a_{1,n} \\ a_{2,1} & a_{2,2} & \dots & a_{2,n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n,1} & a_{n,2} & \dots & a_{n,n} \end{pmatrix},$$
我们考虑它的所有左上子矩阵(upper left submatrices)\footnote{
译者注：它们的行列式被称为“顺序主子式”。
}
$$A_1 = (a_{1,1}),\quad A_2 = \begin{pmatrix} a_{1,1} & a_{1,2} \\ a_{2,1} & a_{2,2} \end{pmatrix},\quad A_3 = \begin{pmatrix} a_{1,1} & a_{1,2} & a_{1,3} \\ a_{2,1} & a_{2,2} & a_{2,3} \\ a_{3,1} & a_{3,2} & a_{3,3} \end{pmatrix}, \dots,\quad A_n = A.$$

\textbf{定理 4.2} ~~塞尔维斯特正定性判据(Sylvester’s Criterion of Positivity)

矩阵 $A = A^*$ 是正定的，当且仅当 $$\det A_k > 0 \quad\text{对所有}\quad k = 1, 2, \dots, n.$$

首先，我们注意到，如果 $A > 0$，那么 $A_k > 0$ 也成立（你能解释为什么吗？）。因此，由于正定矩阵的所有特征值都是正的，参见定理 4.1，$\det A_k > 0$ 对所有 $k = 1, 2, \dots, n$.~

我们可以证明，如果 $\det A_k > 0 \forall k$，那么 $A$ 的所有特征值都是正的，通过分析使用行和列运算进行的二次型对角化，该方法在第 2.2 节中已有所描述。关键在于观察到，如果我们按自然顺序执行行/列运算（即先从所有其他行/列减去第一行/列，然后从第 3, 4, ..., n 行/列减去第二行/列，依此类推），并且我们不进行任何行交换，那么我们也自动地对角化了子二次型 $A_k$.~也就是说，在减去第一行和第二行（以及列）后，我们得到了 $A_2$ 的对角化；在减去第三行/列后，我们得到了 $A_3$ 的对角化，依此类推。

由于我们只执行行替换，我们不会改变行列式。而且，由于我们不执行行交换并以正确的顺序执行运算，我们保留了 $A_k$ 的行列式。因此，条件 $\det A_k > 0$ 保证了每个新的对角线元素都是正的。

当然，必须确保我们只能使用行替换，并按正确的顺序执行运算，即我们不会遇到任何病态情况。如果分析算法，可以看出唯一可能发生的坏情况是在某个步骤中主元位置为零。换句话说，如果我们减去前 $k$ 行和列并得到 $A_k$ 的对角化，那么第 $k+1$ 行和第 $k+1$ 列的元素为 0。我们把证明该情况不可能发生留给读者作为练习。

我们上面概述的证明很简单。然而，让我们更详细地介绍另一种证明，这种证明可以在更高级的教科书中找到。我个人更喜欢第二个证明，因为它展示了一些重要的联系。

我们将需要以下埃尔米特矩阵特征值的一个刻画。


\subsection{4.2. 特征值的极小极大刻画}

回想一下，子空间 $E \subset X$ 的\textbf{余维度}(codimension)被定义为其正交补的维度，$\text{codim } E = \dim(E^\perp)$.~由于对于子空间 $E \subset X$，$\dim X = n$，我们有 $\dim E + \dim E^\perp = n$，所以 $\text{codim } E = \dim X - \dim E$.~

回想一下，平凡子空间 $\{\oo\}$ 的维度为零，因此整个空间 $X$ 的余维度为 0。

\textbf{定理 4.3} （特征值的极小极大刻画）

设 $A = A^*$ 是一个 $n \times n$ 矩阵，设 $\lambda_1 \ge \lambda_2 \ge \dots \ge \lambda_n$ 是其特征值（按降序排列）。那么
$$\lambda_k = \max_{E: \atop \dim E = k} \min_{\xx \in E \atop \|\xx\|=1} (A\xx, \xx) = \min_{F: \atop \text{codim } F = k-1} \max_{\xx \in F \atop \|\xx\|=1} (A\xx, \xx).$$

我们更详细地解释一下像 $\max \min$ 和 $\min \max$ 这样的表达式的含义。为了计算第一个，我们需要考虑所有维度为 $k$ 的子空间 $E$.~对于每个这样的子空间 $E$，我们考虑所有范数为 1 的 $\xx \in E$ 的集合，并找到 $(A\xx, \xx)$ 在所有这些 $\xx$ 上的最小值。因此，对于每个子空间，我们得到一个数字，我们需要选择一个子空间 $E$ 使得该数字最大。这就是 $\max \min$.~

$\min \max$ 的定义类似。

\textbf{注记}~~
一个敏锐的读者可能会注意到一个问题：为什么最大值和最小值存在？众所周知，最大值和最小值往往不存在：例如，函数 $f(x) = x$ 在开区间 $(0, 1)$ 上既没有最大值也没有最小值。

然而，在这种情况下，最大值和最小值确实存在。
存在两种解释 $(A\xx, \xx)$ 达到最大值和最小值：
第一种需要对分析的基本概念有一定的熟悉度：只需说明 $E$ 中的单位球面，即集合 $\{\xx \in E : \|\xx\| = 1\}$ 是紧致的，而一个连续函数（在这种情况下，我们的 $Q[\xx] = (A\xx, \xx)$）在紧致集上会达到其最大值和最小值。

另一种解释是注意到函数 $Q[\xx] = (A\xx, \xx)$，$\xx \in E$，是 $E$ 上的一个二次型。在 $E$ 的某个标准正交基下计算该二次型的矩阵并不难，但让我们仅指出该矩阵不是 $A$：它必须是一个 $k \times k$ 矩阵，其中 $k = \dim E$.~

容易看出，对于二次型，在单位球体上的最大值和最小值是其矩阵的最大和最小特征值。

至于在所有子空间上的优化，我们将在下面证明最大值和最小值确实存在。


\textbf{定理 4.3 的证明}~~
首先，通过选择适当的标准正交基，我们可以无损地假设矩阵 $A$ 是对角矩阵，$A = \text{diag}\{\lambda_1, \lambda_2, \dots, \lambda_n\}$.~

选择维度为 $k$ 的子空间 $E$ 和余维度为 $k-1$ 的子空间 $F$（即 $\dim F = n - (k-1) = n - k + 1$）。由于 $\dim E + \dim F = k + n - k + 1 = n+1 > n$，存在一个非零向量 $\xx_0 \in E \cap F$.~通过归一化它可以无损地假设 $\|\xx_0\| = 1$.~
我们可以总是将特征值按降序排列，所以假设 $\lambda_1 \ge \lambda_2 \ge \dots \ge \lambda_n$.~

由于 $\xx$ 属于 $E$ 和 $F$ 两个子空间，
$$\min_{\xx \in E,\atop \|\xx\|=1} (A\xx, \xx) \le (A\xx_0, \xx_0) \le \max_{\xx \in F,\atop \|\xx\|=1} (A\xx, \xx).$$
我们没有对子空间 $E$ 和 $F$ 做出任何除了维度之外的假设，所以上述不等式
$$(4.2)\quad\min_{\xx \in E,\atop \|\xx\|=1} (A\xx, \xx) \le \max_{\xx \in F,\atop \|\xx\|=1} (A\xx, \xx)$$
对所有适当维度的 $E$ 和 $F$ 的对都成立。

定义 $$E_0 := \text{span}\{\ee_1, \ee_2, \dots, \ee_k\},\quad F_0 := \text{span}\{\ee_k, \ee_{k+1}, \dots, \ee_n\}.$$

由于对于自伴矩阵 $B$，$(B\xx, \xx)$ 在单位球体 $\{\xx : \|\xx\|=1\}$ 上的最大值和最小值分别是最大和最小特征值（在对角矩阵上很容易验证），我们得到
$$\min_{\xx \in E_0,\atop \|\xx\|=1} (A\xx, \xx) = \max_{\xx \in F_0,\atop \|\xx\|=1} (A\xx, \xx) = \lambda_k.$$
从（4.2）可知，对于任何子空间 $E$，$\dim E = k$，
$$\min_{\xx \in E, \|\xx\|=1} (A\xx, \xx) \le \max_{\xx \in F_0, \|\xx\|=1} (A\xx, \xx) = \lambda_k.$$
同理，对于任何余维度为 $k-1$ 的子空间 $F$，
$$\max_{\xx \in F, \|\xx\|=1} (A\xx, \xx) \ge \min_{\xx \in E_0, \|\xx\|=1} (A\xx, \xx) = \lambda_k.$$
但是在子空间 $E_0$ 和 $F_0$ 上，最大值和最小值都是 $\lambda_k$，所以 $\min \max = \max \min = \lambda_k$.~

\textbf{推论4.4. 特征值的交错性质}~~

设 $A = A^* = \{a_{j,k}\}^{n}_{j,k=1}$ 是一个自伴矩阵，令 $\tilde{A} = \{a_{j,k}\}^{n-1}_{j,k=1}$ 是它的大小为 $(n-1) \times (n-1)$ 的子矩阵（移除最后一行和最后一列）。设 $\lambda_1, \lambda_2, \dots, \lambda_n$ 和 $\mu_1, \mu_2, \dots, \mu_{n-1}$ 分别是 $A$ 和 $\tilde{A}$ 的特征值（按降序排列）。那么
$$\lambda_1 \ge \mu_1 \ge \lambda_2 \ge \mu_2 \ge \dots \ge \lambda_{n-1} \ge \mu_{n-1} \ge \lambda_n,$$
即 
$$\lambda_k \ge \mu_k \ge \lambda_{k+1},\quad k = 1, 2, \dots, n-1.$$

\textbf{证明}~~

设 $\tilde{X} \subset \FF^n$ 是由前 $n-1$ 个基向量张成的子空间，$\tilde{X} = \text{span}\{\ee_1, \ee_2, \dots, \ee_{n-1}\}$.~由于 $( \tilde{A} \xx, \xx ) = ( A \xx, \xx )$ 对所有 $\xx \in \tilde{X}$ 成立，定理 4.3 暗示
$$\mu_k = \max_{E \subset \tilde{X},\atop \dim E = k} \min_{\xx \in E,\atop \|\xx\|=1} (A\xx, \xx).$$
为了得到 $\lambda_k$，我们需要在 $\FF^n$ 的所有维度为 $k$ 的子空间上取最大值（任何 $\tilde{X}$ 的子空间都是 $\FF^n$ 的子空间）。因此，$$\mu_k \le \lambda_k.$$ （最大值只能增加，如果我们增加集合的话）。

另一方面，$\tilde{X}$ 中余维度为 $k-1$ 的任何子空间 $E$（这里指的是在 $\tilde{X}$ 中的余维度）的维度是 $n-1 - (k-1) = n-k$，因此它在 $\FF^n$ 中的余维度是 $k$.~所以
$$\mu_k = \min_{E \subset \tilde{X},\atop \dim E = n-k} \max_{\xx \in E,\atop \|\xx\|=1} (A\xx, \xx) \le \min_{E \subset \FF^n,\atop \dim E = n-k} \max_{\xx \in E,\atop \|\xx\|=1} (A\xx, \xx) = \lambda_{k+1}$$
 （在更大集合上的最小值只能更小）。

\textbf{定理 4.2 的证明}~~
如果 $A > 0$，那么 $A_k > 0$ 对 $k=1, 2, \dots, n$ 也成立（你能解释为什么吗？）。由于正定矩阵的所有特征值都是正的（见定理 4.1），$\det A_k > 0$ 对所有 $k=1, 2, \dots, n$.~

现在我们来证明另一个蕴含。设 $\det A_k > 0$ 对所有 $k$.~我们将通过归纳法证明（对 $k$），所有 $A_k$（因此 $A = A_n$）都是正定的。

显然 $A_1$ 是正定的（它是一个 $1 \times 1$ 矩阵，所以 $A_1 = \det A_1$）。假设 $A_{k-1} > 0$（且 $\det A_k > 0$），我们来证明 $A_k$ 是正定的。
设 $\lambda_1, \lambda_2, \dots, \lambda_k$ 和 $\mu_1, \mu_2, \dots, \mu_{k-1}$ 分别是 $A_k$ 和 $A_{k-1}$ 的特征值。根据推论 4.4，
$$\lambda_j \ge \mu_j > 0,\quad j = 1, 2, \dots, k-1.$$
由于 $\det A_k = \lambda_1 \lambda_2 \dots \lambda_{k-1} \lambda_k > 0$，最后一个特征值 $\lambda_k$ 也必须是正的。
因此，由于其所有特征值都为正，矩阵 $A_k$ 是正定的。

\subsection{4.3. 一些注记}
首先，请注意，塞尔维斯特正定性判据不能推广到半正定矩阵（当 $n \ge 3$ 时），这意味着对于 $n \times n$ 矩阵，$n \ge 3$，条件 $\det A_k \ge 0$ 并不蕴含 $A$ 是半正定的，参见下面的问题 4.4。

对于 $2 \times 2$ 矩阵，然而，条件 $\det A_k \ge 0$ 蕴含 $A$ 是半正定的，参见下面的问题 4.3。
这有时会导致对 $n \times n$ 矩阵的错误结论。

最后，我们应该简单地谈谈负定矩阵。这是一个典型的学生错误，认为条件 $\det A_k < 0$ 意味着 $A$ 是负定的。但这却是错误的！

要检查矩阵 $A$ 是否是负定的，只需检查矩阵 $-A$ 是否是正定的。
将 塞尔维斯特正定性判据应用于 $-A$，我们可以看到 $A$ 是负定的，当且仅当 $(-1)^k \det A_k > 0$ 对所有 $k = 1, 2, \dots, n$.~

\begin{exer} \textbf{练习}~~

4.1. 使用塞尔维斯特正定性判据检查矩阵 
$$A = \begin{pmatrix} 4 & 2 & 1 \\ 2 & 3 & -1 \\ 1 & -1 & 2 \end{pmatrix},\quad B = \begin{pmatrix} 3 & -1 & 2 \\ -1 & 4 & -2 \\ 2 & -2 & 1 \end{pmatrix}$$
否是正定的。

矩阵 $-A$, $A^3$ 和 $A^{-1}$, $A+B^{-1}$, $A+B$, $A-B$ 是否是正定的？

4.2. 判断正误：

a) 如果 $A$ 是正定的，那么 $A^5$ 是正定的。

b) 如果 $A$ 是负定的，那么 $A^8$ 是负定的。

c) 如果 $A$ 是负定的，那么 $A^{12}$ 是正定的。

d) 如果 $A$ 是正定的，且 $B$ 是半负定的，那么 $A-B$ 是正定的。

e) 如果 $A$ 是不定的，且 $B$ 是正定的，那么 $A+B$ 是不定的。

4.3. 设 $A$ 是一个 $2 \times 2$ 埃尔米特矩阵，满足 $a_{1,1} \ge 0$, $\det A \ge 0$.~证明 $A$ 是半正定的。

4.4. 找一个$n \times n$ 实对称 矩阵 $A$，使得 $\det A_k \ge 0$ 对所有 $k = 1, 2, \dots, n$，但是矩阵 $A$ 不是半正定的。注意 $n$ 至少为 3，参见上面的问题 4.3。

4.5. 设 $A$ 是一个 $n \times n$ 埃尔米特矩阵，使得对所有 $k = 1, 2, \dots, n-1$，都有 $\det A_k > 0$，并且 $\det A \ge 0$.~证明 $A$ 是半正定的。

4.6. 找到一个 $3 \times 3$ 实对称矩阵 $A$，使得 $a_{1,1} > 0$，对 $k=2,3$ 有 $\det A_k \ge 0$，但矩阵 $A$ 不是半正定的。
\end{exer}

\section{5. 正定二次型与内积}

设 $V$ 是一个内积空间，设 $\B = \{\vv_1, \vv_2, \dots, \vv_n\}$ 是 $V$ 中的一个基（不一定是正交的）。设 $G = \{g_{j,k}\}^{n}_{j,k=1}$ 是由 $$g_{j,k} = (\vv_k, \vv_j)$$ 
定义的矩阵。

如果 $\xx = \sum_{k=1}^n x_k \vv_k$ 且 $\yy = \sum_{j=1}^n y_j \vv_j$，那么
\begin{equation} \notag
\begin{split}
(\xx, \yy) = (\sum_{k=1}^n x_k \vv_k, \sum_{j=1}^n y_j \vv_j) =&\ \sum_{k,j=1}^n x_k y_j (\vv_k, \vv_j)\\ =&\ \sum_{j=1}^n \sum_{k=1}^n g_{j,k} x_k y_j = (G [\xx]_\B, [\yy]_\B)_{\CC^n},
\end{split}\end{equation}
其中 $( \cdot, \cdot )_{\CC^n}$ 代表 $\CC^n$ 中的标准内积。
可以立即看出 $G$ 是一个正定矩阵（为什么？）。

因此，当在内积空间中的任意（不一定是正交的）基下处理坐标时，内积（用坐标表示）不是像在 $\CC^n$ 中那样通过标准内积计算，而是通过如上所述的正定矩阵 $G$ 来计算。

注意，这个 $G$-内积当且仅当 $G=I$ 时才与 $\CC^n$ 中的标准内积重合，这当且仅当基 $\vv_1, \vv_2, \dots, \vv_n$ 是标准正交的时成立。

反之，给定一个正定矩阵 $G$，可以在 $\CC^n$ 中定义一个非标准的内积（$G$-内积）为 
$$(\xx, \yy)_G := (G\xx, \yy)_{\CC^n},\quad \xx, \yy \in \CC^n.$$
可以很容易地检查 $(\xx, \yy)_G$ 确实是一个内积，即满足第 5 章第 1.3 节性质 1-4.
